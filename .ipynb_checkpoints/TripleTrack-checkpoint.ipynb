{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 534\n",
      "Pre-processing...\n",
      "\n",
      "2:   Um you guys have met me\n",
      "stop words: you, have, me, \n",
      "\n",
      "Triple for Query   : you guys - meet - me\n",
      "me -PRON- PRON PRP ROOT xx True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5bcf617ba71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;31m# query with only a part of the triple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0mComponentQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m \u001b[0mPartialQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-5bcf617ba71d>\u001b[0m in \u001b[0;36mPartialQuery\u001b[0;34m(subj, pred, obj)\u001b[0m\n\u001b[1;32m    215\u001b[0m         qAsk = prefix + \"\"\"\n\u001b[1;32m    216\u001b[0m         ASK {\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"\"\" + FormatURI(subj) + \"\"\"\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"\"\" + FormatURI(pred, True) + \"\"\"\u001b[0m \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"\"\" + FormatURI(token.lemma) + \"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         }\"\"\"\n\u001b[1;32m    219\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqAsk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prefix' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from owlready2 import *\n",
    "import rdflib\n",
    "\n",
    "import re\n",
    "\n",
    "# pre-processing\n",
    "def PreProcess(senSet):\n",
    "    #remove content between [ ]\n",
    "    print(\"Pre-processing...\")\n",
    "    for index in range(len(senSet)):\n",
    "        while senSet[index].find('[')>=0:\n",
    "            i_start = senSet[index].find('[')\n",
    "            i_end = senSet[index].find(']')\n",
    "            s = senSet[index][i_start:i_end+2]\n",
    "            senSet[index] = senSet[index].replace(s, \"\")\n",
    "            \n",
    "# stopwords from parsing the whole sentence\n",
    "def RemoveStopword1(phrase, doc, chunkStart, chunkEnd, stopList):\n",
    "    result = phrase\n",
    "    i_stop=0\n",
    "    #start = chunk.start# to eliminate the condition when the first word of chunk is stop word\n",
    "    for i_sen in range(chunkStart, chunkEnd):\n",
    "        while i_stop < len(stopList) and stopList[i_stop] < i_sen-1:\n",
    "            #print(str(stopList[i_stop]) + ' ' + str(i_sen))\n",
    "            i_stop = i_stop+1\n",
    "        # there is no stop word in current chunk\n",
    "        if i_stop >= len(stopList):\n",
    "            break;\n",
    "        #print(i_sen)\n",
    "        # finish going through the chunk\n",
    "        if stopList[i_stop] > chunkEnd-1:\n",
    "            break\n",
    "        # find the stop word and remove it\n",
    "        if stopList[i_stop] == i_sen-1:\n",
    "            #print(doc[i_sen-1])\n",
    "            if i_sen-1 == chunkStart:\n",
    "                result = result.replace(doc[i_sen-1].text + ' ', '')\n",
    "                chunkStart = chunkStart+1\n",
    "            else:\n",
    "                result = result.replace(' ' + doc[i_sen-1].text, '')\n",
    "    return result\n",
    "\n",
    "# stopwords from parsing triple separately\n",
    "def RemoveStopword2(inputPhrase):\n",
    "    result = ''\n",
    "    doc_phrase = nlp(str(inputPhrase))\n",
    "    for token in doc_phrase:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #       token.shape_, token.is_alpha, token.is_stop)\n",
    "        if not token.is_stop:\n",
    "            result = result + token.text + ' '\n",
    "        #else:\n",
    "        #    print(token.text + ', ', end = '')    \n",
    "    return result\n",
    "\n",
    "\n",
    "# extract one triple from given sentence\n",
    "def ExtractTriple(sen):\n",
    "    # initialize the triple and stop word list\n",
    "    subj = \"\"\n",
    "    pred = \"\"\n",
    "    obj = \"\"\n",
    "    stopList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + ': ' + senSet[index])\n",
    "    \n",
    "    ## visualize the semantic tree\n",
    "    #options = {'compact': True, 'color': 'blue'}\n",
    "    #displacy.serve(doc, style='dep', options=options)\n",
    "    #displacy.serve(doc, style='dep')\n",
    "\n",
    "    print('stop words: ', end='')\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "        # record the index of stop words\n",
    "        if token.is_stop:\n",
    "            print(token.text + ', ', end='')\n",
    "            stopList.append(token.i)\n",
    "        if re.match('nsubj', token.dep_):   \n",
    "            subj = token.text\n",
    "        if re.match('ROOT', token.dep_): \n",
    "            pred = token.lemma_\n",
    "            pred_orig = token.text\n",
    "        if re.match('dobj', token.dep_): \n",
    "            obj = token.text\n",
    "            '''#an earlier solution that I find not necessary\n",
    "            obj = token.lemma_\n",
    "            # to avoid cases like \"-PRON-\"\n",
    "            if obj[0] == '-':\n",
    "                obj = token.text'''\n",
    "    print('\\n')\n",
    "\n",
    "    subj_1 = subj\n",
    "    obj_1 = obj\n",
    "    # using chunk to update subject and object\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.head.text == pred_orig and re.match('nsubj', chunk.root.dep_):\n",
    "            subj = chunk.text\n",
    "            # remove stop words\n",
    "            subj_1 = RemoveStopword1(subj, doc, chunk.start, chunk.end, stopList)\n",
    "\n",
    "        if chunk.root.head.text == pred_orig and re.match('dobj|attr', chunk.root.dep_):\n",
    "            obj = chunk.text\n",
    "            # remove stop words\n",
    "            obj_1 = RemoveStopword1(obj, doc, chunk.start, chunk.end, stopList)\n",
    "        #print(chunk.text + ' ' + str(chunk.start))\n",
    "        #print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
    "\n",
    "    #print('Before : ' + subj + ' - ' + pred + ' - ' + obj)\n",
    "    #print('Method1: ' + subj_1 + ' - ' + pred + ' - ' + obj_1)\n",
    "\n",
    "    # second method to remove stop words\n",
    "    subj_2 = RemoveStopword2(subj)\n",
    "    obj_2 = RemoveStopword2(obj)\n",
    "    #print('Method2: ' + subj_2 + '- ' + pred + ' - ' + obj_2 + '\\n')\n",
    "\n",
    "    return [subj, pred, obj]\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def FormatURI(phrase, isPred = False):\n",
    "    #print('Before formatting:  ' + phrase)\n",
    "    chars = list(phrase)\n",
    "    if len(chars) > 0 and not isPred:\n",
    "        chars[0] = chars[0].upper()\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == ' ' and i+1 < len(chars):\n",
    "            chars[i+1] = chars[i+1].upper()\n",
    "    phrase = ''.join(chars)\n",
    "    phrase = phrase.replace(' ', '')\n",
    "    phrase = re.sub(r'[^a-zA-Z0-9\\s]', '', phrase)\n",
    "    #print('After formatting:  ' + phrase)\n",
    "    return phrase\n",
    "\n",
    "# query the given triple in the ontology with SPARQL\n",
    "# return true/false as result\n",
    "def QueryTriple(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    #subj = \"provinceLink\"\n",
    "    pred = \"range\"\n",
    "    #obj = \"Province\"\n",
    "    qSelect = prefix + \"\"\"\n",
    "    SELECT ?sub WHERE {\n",
    "      ?sub rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    qAsk = prefix + \"\"\"\n",
    "    ASK {\n",
    "        dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    \n",
    "    r = list(m_graph.query(qAsk))\n",
    "    return r\n",
    "\n",
    "def ComponentQuery(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    #subj = \"provinceLink\"\n",
    "    #pred = \"range\"\n",
    "    #obj = \"province\"\n",
    "    \n",
    "    qAsk = prefix + \"\"\"\n",
    "    ASK {\n",
    "        dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred, True) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    \n",
    "    qSelect_S = prefix + \"\"\"\n",
    "    SELECT ?sub WHERE {\n",
    "      ?sub rdf:\"\"\" + FormatURI(pred, True) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    \n",
    "    qSelect_P = prefix + \"\"\"\n",
    "    SELECT ?pred WHERE {\n",
    "      dbpd:\"\"\" + FormatURI(subj) + \"\"\" ?pred dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    \n",
    "    qSelect_O = prefix + \"\"\"\n",
    "    SELECT ?obj WHERE {\n",
    "      dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred, True) + \"\"\" ?obj.\n",
    "    }\"\"\"\n",
    "    \n",
    "    qSelect_S_P = prefix + \"\"\"\n",
    "    SELECT ?sub ?pred WHERE {\n",
    "      ?sub ?pred dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "    }\"\"\"\n",
    "    \n",
    "    qSelect_S_O = prefix + \"\"\"\n",
    "    SELECT ?sub ?obj WHERE {\n",
    "      ?sub rdf:\"\"\" + FormatURI(pred, True) + \"\"\" ?obj.\n",
    "    }\"\"\"\n",
    "    \n",
    "    #print(qSelect_S_P)\n",
    "    r = list(m_graph.query(qSelect_S_P))\n",
    "    if r!=[]:\n",
    "        print(r)\n",
    "    return r\n",
    "\n",
    "def PartialQuery(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \n",
    "    doc = nlp(str(obj))\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "              token.shape_, token.is_alpha, token.is_stop)\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred, True) + \"\"\" dbpd:\"\"\" + FormatURI(token.lemma) + \"\"\".\n",
    "        }\"\"\"\n",
    "        print(qAsk)\n",
    "        r = \"\"\n",
    "    \n",
    "    return r\n",
    "\n",
    "# load Spacy NLP dictionary\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load DBPD ontology and construct graph for query\n",
    "m_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "m_onto = m_world.get_ontology(\"dbpedia.owl\").load()\n",
    "m_graph = m_world.as_rdflib_graph()\n",
    "\n",
    "# load data\n",
    "#file = open(\"shortdataset.csv\", \"r\")\n",
    "file = open(\"newdataset_formatted.csv\", \"r\")\n",
    "reader = csv.reader(file)\n",
    "senSet = []\n",
    "for item in reader:\n",
    "    #format sentences in item as string\n",
    "    fullP = \"\".join(item)\n",
    "    splitP = fullP.split(\";\", 3);\n",
    "    splitS = splitP[3][1:len(splitP[3])].split(\".\");\n",
    "    #print(splitS)\n",
    "    for sen in splitS:\n",
    "        senSet.append(sen)#store the sentence into an array\n",
    "file.close()\n",
    "print(\"Total sentences: \" + str(len(senSet)))\n",
    "\n",
    "# pre-processing\n",
    "PreProcess(senSet)\n",
    "\n",
    "# parse and query each sentence\n",
    "#for index in range(len(senSet)):\n",
    "index = 2\n",
    "\n",
    "# extract triple from current sentence\n",
    "[subj, pred, obj] = ExtractTriple(senSet[index])\n",
    "print('Triple for Query   : ' + subj + ' - ' + pred + ' - ' + obj)\n",
    "\n",
    "# query the triple in dbpd with SPARQL\n",
    "queryResult = QueryTriple(subj, pred, obj)\n",
    "# print('Triple Query Result: ' + str(queryResult))\n",
    "\n",
    "# query with only a part of the triple\n",
    "ComponentQuery(subj, pred, obj)\n",
    "PartialQuery(subj, pred, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to remove WARNINGs from Owlready2\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "DESCRIBE not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b27ce1a90687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m DESCRIBE ?sub WHERE {\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m?\u001b[0m\u001b[0msub\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m  \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvince\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m }\"\"\"))\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         return result(processor.query(\n\u001b[0;32m-> 1089\u001b[0;31m             query_object, initBindings, initNs, **kwargs))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     def update(self, update_object, processor='sparql',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/processor.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrOrQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevalQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitBindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalQuery\u001b[0;34m(graph, query, initBindings, base)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevalPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalPart\u001b[0;34m(ctx, part)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DescribeQuery'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DESCRIBE not implemented'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: DESCRIBE not implemented"
     ]
    }
   ],
   "source": [
    "# reference: https://pythonhosted.org/Owlready2/world.html\n",
    "from owlready2 import *\n",
    "import rdflib\n",
    "\n",
    "my_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "onto = my_world.get_ontology(\"dbpedia.owl\").load()\n",
    "\n",
    "graph = my_world.as_rdflib_graph()\n",
    "print(len(graph))\n",
    "\n",
    "prefix = \"\"\"\n",
    "PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "SELECT ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "ASK {\n",
    "  dbpd:provinceLink rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "r = list(graph.query(prefix + \"\"\"\n",
    "DESCRIBE ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))\n",
    "\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
