{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cso.kmi.open.ac.uk/schema/cso#Topic\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "#sparql = SPARQLWrapper(\"dbpedia.owl\")\n",
    "sparql = SPARQLWrapper(\"http://localhost:8890/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?label\n",
    "    WHERE { <https://cso.kmi.open.ac.uk/topics/robotics> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?label }\n",
    "\"\"\")\n",
    "# SELECT * WHERE {\n",
    "#        ?s ?p ?o .\n",
    "#}\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"label\"][\"value\"])\n",
    "    #print(result[\"thumb\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 46\n",
      "Pre-processing...\n",
      "\n",
      "26. Original Sentence:\n",
      "Neverland has the tree house.\n",
      "['Neverland', 'tree house']\n",
      "\n",
      "For \"Neverland\":\n",
      "0: Peter Pan (1953 film)\n",
      "1: Annihilator (band)\n",
      "2: Finding Neverland\n",
      "3: Neverland\n",
      "4: Neverland Ranch\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 3\n",
      "\n",
      "\n",
      "\n",
      "For \"tree house\":\n",
      "0: Tree house\n",
      "1: List of monarchs of Mercia\n",
      "2: Treehouse of Horror\n",
      "3: Wuffingas\n",
      "4: Magic Tree House series\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/ontology/Neverland>', '<http://dbpedia.org/ontology/Tree_house>']\n"
     ]
    },
    {
     "ename": "QueryBadFormed",
     "evalue": "QueryBadFormed: a bad request has been sent to the endpoint, probably the sparql query is bad formed. \n\nResponse:\nb\"Virtuoso 37000 Error SP030: SPARQL compiler, line 6: Undefined namespace prefix at 'dbo' before '?abstract'\\n\\nSPARQL query:\\ndefine sql:big-data-const 0 \\n#output-format:application/sparql-results+json\\n\\n        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\n        SELECT ?abstract ?thumb\\n        WHERE {<http://dbpedia.org/ontology/Neverland> dbo:abstract ?abstract .<http://dbpedia.org/ontology/Neverland> dbo:thumbnail ?thumb .\\n        FILTER (lang(?abstract) = 'en')\\n        }\\n    \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/SPARQLWrapper/Wrapper.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mQueryBadFormed\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4ba5a9819890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mcurKey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&-&\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mQueryInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentityInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0moutputList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentityInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4ba5a9819890>\u001b[0m in \u001b[0;36mQueryInfo\u001b[0;34m(URI, entityInfo)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \"\"\")\n\u001b[1;32m    483\u001b[0m     \u001b[0msparql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetReturnFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bindings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/SPARQLWrapper/Wrapper.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mQueryResult\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQueryResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueryAndConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/SPARQLWrapper/Wrapper.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryBadFormed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEndPointNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mQueryBadFormed\u001b[0m: QueryBadFormed: a bad request has been sent to the endpoint, probably the sparql query is bad formed. \n\nResponse:\nb\"Virtuoso 37000 Error SP030: SPARQL compiler, line 6: Undefined namespace prefix at 'dbo' before '?abstract'\\n\\nSPARQL query:\\ndefine sql:big-data-const 0 \\n#output-format:application/sparql-results+json\\n\\n        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\n        SELECT ?abstract ?thumb\\n        WHERE {<http://dbpedia.org/ontology/Neverland> dbo:abstract ?abstract .<http://dbpedia.org/ontology/Neverland> dbo:thumbnail ?thumb .\\n        FILTER (lang(?abstract) = 'en')\\n        }\\n    \""
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "import json\n",
    "\n",
    "import urllib\n",
    "#from owlready2 import *\n",
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from allennlp.common.testing import AllenNlpTestCase\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# pre-processing\n",
    "def PreProcess(senSet):\n",
    "    #remove content between [ ]\n",
    "    print(\"Pre-processing...\")\n",
    "    for index in range(len(senSet)):\n",
    "        while senSet[index].find('[')>=0:\n",
    "            i_start = senSet[index].find('[')\n",
    "            i_end = senSet[index].find(']')\n",
    "            s = senSet[index][i_start:i_end+2]\n",
    "            senSet[index] = senSet[index].replace(s, \"\")\n",
    "            \n",
    "# stopwords from parsing the whole sentence\n",
    "def RemoveStopword1(phrase, doc, chunkStart, chunkEnd, stopList):\n",
    "    result = phrase\n",
    "    i_stop=0\n",
    "    #start = chunk.start# to eliminate the condition when the first word of chunk is stop word\n",
    "    for i_sen in range(chunkStart, chunkEnd):\n",
    "        while i_stop < len(stopList) and stopList[i_stop] < i_sen-1:\n",
    "            #print(str(stopList[i_stop]) + ' ' + str(i_sen))\n",
    "            i_stop = i_stop+1\n",
    "        # there is no stop word in current chunk\n",
    "        if i_stop >= len(stopList):\n",
    "            break;\n",
    "        #print(i_sen)\n",
    "        # finish going through the chunk\n",
    "        if stopList[i_stop] > chunkEnd-1:\n",
    "            break\n",
    "        # find the stop word and remove it\n",
    "        if stopList[i_stop] == i_sen-1:\n",
    "            #print(doc[i_sen-1])\n",
    "            if i_sen-1 == chunkStart:\n",
    "                result = result.replace(doc[i_sen-1].text + ' ', '')\n",
    "                chunkStart = chunkStart+1\n",
    "            else:\n",
    "                result = result.replace(' ' + doc[i_sen-1].text, '')\n",
    "    return result\n",
    "\n",
    "# stopwords from parsing triple separately\n",
    "def RemoveStopword2(inputPhrase):\n",
    "    result = ''\n",
    "    doc_phrase = nlp(str(inputPhrase))\n",
    "    for token in doc_phrase:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #       token.shape_, token.is_alpha, token.is_stop)\n",
    "        if not token.is_stop:\n",
    "            result = result + token.text + ' '\n",
    "        #else:\n",
    "        #    print(token.text + ', ', end = '')    \n",
    "    return result\n",
    "\n",
    "\n",
    "# extract one triple from given sentence\n",
    "def ExtractTriple(sen):\n",
    "    # initialize the triple and stop word list\n",
    "    subj = \"\"\n",
    "    pred = \"\"\n",
    "    obj = \"\"\n",
    "    stopList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "    \n",
    "    ## visualize the semantic tree\n",
    "    #options = {'compact': True, 'color': 'blue'}\n",
    "    #displacy.serve(doc, style='dep', options=options)\n",
    "    #displacy.serve(doc, style='dep')\n",
    "\n",
    "    print('\\nStopwords:')\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "        # record the index of stop words\n",
    "        if token.is_stop:\n",
    "            print(token.text + ', ', end='')\n",
    "            stopList.append(token.i)\n",
    "        if re.match('nsubj', token.dep_):   \n",
    "            subj = token.text\n",
    "        if re.match('ROOT', token.dep_): \n",
    "            pred = token.lemma_\n",
    "            pred_orig = token.text\n",
    "        if re.match('dobj', token.dep_): \n",
    "            obj = token.text\n",
    "            '''#an earlier solution that I find not necessary\n",
    "            obj = token.lemma_\n",
    "            # to avoid cases like \"-PRON-\"\n",
    "            if obj[0] == '-':\n",
    "                obj = token.text'''\n",
    "    print('\\n')\n",
    "\n",
    "    subj_1 = subj\n",
    "    obj_1 = obj\n",
    "    # using chunk to update subject and object\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.head.text == pred_orig and re.match('nsubj', chunk.root.dep_):\n",
    "            subj = chunk.text\n",
    "            # remove stop words\n",
    "            subj_1 = RemoveStopword1(subj, doc, chunk.start, chunk.end, stopList)\n",
    "\n",
    "        if chunk.root.head.text == pred_orig and re.match('dobj|attr', chunk.root.dep_):\n",
    "            obj = chunk.text\n",
    "            # remove stop words\n",
    "            obj_1 = RemoveStopword1(obj, doc, chunk.start, chunk.end, stopList)\n",
    "        #print(chunk.text + ' ' + str(chunk.start))\n",
    "        #print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
    "\n",
    "    #print('Before : ' + subj + ' - ' + pred + ' - ' + obj)\n",
    "    #print('Method1: ' + subj_1 + ' - ' + pred + ' - ' + obj_1)\n",
    "\n",
    "    # second method to remove stop words\n",
    "    subj_2 = RemoveStopword2(subj)\n",
    "    obj_2 = RemoveStopword2(obj)\n",
    "    #print('Method2: ' + subj_2 + '- ' + pred + ' - ' + obj_2 + '\\n')\n",
    "\n",
    "    return [subj, pred, obj]\n",
    "\n",
    "def QueryURI(keywords, index=-2):\n",
    "    localSite = 'http://localhost:1111/api/search/KeywordSearch?'\n",
    "    onlineSite = 'http://lookup.dbpedia.org/api/search/KeywordSearch?'\n",
    "    prefix = \"{http://lookup.dbpedia.org/}\"\n",
    "    \n",
    "    keywords = keywords.replace(' ', \"%20\")\n",
    "    request = onlineSite + \\\n",
    "    'QueryClass='   + ''  + \\\n",
    "    '&MaxHits='     + '5' + \\\n",
    "    '&QueryString=' + keywords\n",
    "    response = str(urllib.request.urlopen(request).read(), 'utf-8')\n",
    "\n",
    "    root = ET.fromstring(response)\n",
    "    result = root.findall(prefix + \"Result\")\n",
    "    \n",
    "    if len(result)>0:\n",
    "        selected = -1\n",
    "        count = 0\n",
    "        for name in result:\n",
    "            print(str(count) + \": \" + name.find(prefix + \"Label\").text)\n",
    "            count += 1\n",
    "        # for some default input during debugging\n",
    "        if index<-1:\n",
    "            index = int(input(\"Which one is closer to what you mean? (type \\\"-1\\\" if nothing seems correct) \"))\n",
    "        if index >= 0:\n",
    "            selected = \"<\" + result[index].find(prefix + \"URI\").text + \">\"\n",
    "        else:\n",
    "            selected = None\n",
    "        return selected.replace(\"/resource\", \"/ontology\")\n",
    "    else:\n",
    "        print(\"Sorry, we find nothing for this stuff :(\\n\")\n",
    "        return None\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def FormatURI(phrase, isS_O = False):\n",
    "    #print('Before formatting:  ' + phrase)\n",
    "    chars = list(phrase)\n",
    "    \n",
    "    if len(chars) > 0 and not isS_O:\n",
    "        chars[0] = chars[0].upper()\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == ' ' and i+1 < len(chars):\n",
    "            chars[i+1] = chars[i+1].upper()\n",
    "    phrase = ''.join(chars)\n",
    "    phrase = phrase.replace(' ', '')\n",
    "    phrase = re.sub(r'[^a-zA-Z0-9\\s]', '', phrase)\n",
    "    #print('After formatting:  ' + phrase)\n",
    "    return phrase\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def NameURI(url):\n",
    "    index_slash = 0\n",
    "    for i in range(len(url)-1, -1, -1):\n",
    "        if url[i] == '/':\n",
    "            index_slash = i+1\n",
    "            break\n",
    "    return url[index_slash:]\n",
    "\n",
    "# query the given triple in the ontology with SPARQL\n",
    "# return true/false as result\n",
    "def QueryTriple(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"Province\"\n",
    "        qSelect = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "\n",
    "        r = list(m_graph.query(qAsk))\n",
    "        return r\n",
    "\n",
    "def ComponentQuery1(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    #subj = \"provinceLink\"\n",
    "    #pred = \"range\"\n",
    "    #obj = \"province\"\n",
    "    \n",
    "    r = []\n",
    "    if subj!=None:\n",
    "        qSelect_P_O = prefix + \"\"\"\n",
    "        SELECT ?pred ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred ?obj.\n",
    "        }\"\"\"\n",
    "        #r1 = m_graph.query(qSelect_P_O)\n",
    "        sparql.setQuery(qSelect_P_O)\n",
    "        r1 = sparql.query().convert()\n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if pred!=None:\n",
    "        qSelect_S_O = prefix + \"\"\"\n",
    "        SELECT ?sub ?obj WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        #r2 = m_graph.query(qSelect_S_O) \n",
    "        sparql.setQuery(qSelect_S_O)\n",
    "        r2 = sparql.query().convert()\n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "        \n",
    "    if obj!=None:\n",
    "        qSelect_S_P = prefix + \"\"\"\n",
    "        SELECT ?sub ?pred WHERE {\n",
    "          ?sub ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        #r3 = m_graph.query(qSelect_S_P) \n",
    "        sparql.setQuery(qSelect_S_P)\n",
    "        r3 = sparql.query().convert()\n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "\n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery2(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"    \n",
    "    \n",
    "    r = []\n",
    "    if pred!=None and obj!=None:\n",
    "        qSelect_S = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r1 = m_graph.query(qSelect_S) \n",
    "        sparql.setQuery(qSelect_S)\n",
    "        r1 = sparql.query().convert()\n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if subj!=None and obj!=None:\n",
    "        qSelect_P = prefix + \"\"\"\n",
    "        SELECT ?pred WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r2 = m_graph.query(qSelect_P)\n",
    "        sparql.setQuery(qSelect_P)\n",
    "        r2 = sparql.query().convert()\n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "            \n",
    "    if subj!=None and pred!=None:\n",
    "        qSelect_O = prefix + \"\"\"\n",
    "        SELECT ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r3 = m_graph.query(qSelect_O)\n",
    "        sparql.setQuery(qSelect_O)\n",
    "        r3 = sparql.query().convert()\n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "        \n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    #PrintQueryResult(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery3(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"province\"\n",
    "\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK WHERE {\n",
    "            \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\"\n",
    "        }\"\"\"\n",
    "        #print(qAsk)\n",
    "\n",
    "        #r = m_graph.query(qAsk)\n",
    "        sparql.setQuery(qAsk)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        r = sparql.query().convert()\n",
    "\n",
    "        #if not r:\n",
    "        #    print(qAsk)\n",
    "        #    print(r)\n",
    "        \n",
    "        return r[\"boolean\"]\n",
    "\n",
    "def PartialQuery(subj, pred, obj, subjURI, predURI, objURI):\n",
    "    if subj==None and pred==None and obj==None:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n*********************** In Partial Query *************************\")\n",
    "    doc_subj = nlp(str(subj))\n",
    "    doc_pred = nlp(str(pred))\n",
    "    doc_obj = nlp(str(obj))\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    r3 = False\n",
    "    \n",
    "    for token_subj in doc_subj:\n",
    "        # get the URI for partial subj\n",
    "        if len(doc_subj)>1:\n",
    "            print(\"\\nFor partial subject \\\"\" + token_subj.text + \"\\\":\")\n",
    "            part_subj = QueryURI(token_subj.text)\n",
    "        else:\n",
    "            part_subj = subjURI\n",
    "            \n",
    "        for token_pred in doc_pred:\n",
    "            # get the URI for partial pred\n",
    "            if len(doc_pred)>1:\n",
    "                print(\"\\nFor partial predicate \\\"\" + token_pred.text + \"\\\":\")\n",
    "                part_pred = QueryURI(token_pred.text)\n",
    "            else:\n",
    "                part_pred = predURI\n",
    "                \n",
    "            for token_obj in doc_obj:\n",
    "                #print(token_obj.text, token_obj.lemma_, token_obj.pos_, token_obj.tag_, token_obj.dep_,\n",
    "                #      token_obj.shape_, token_obj.is_alpha, token_obj.is_stop)\n",
    "                if token_subj.is_stop and token_pred.is_stop and token_obj.is_stop:\n",
    "                    continue\n",
    "                    \n",
    "                # get the URI for partial obj\n",
    "                if len(doc_obj)>1:\n",
    "                    print(\"\\nFor partial object \\\"\" + token_obj.text + \"\\\":\")\n",
    "                    part_obj = QueryURI(token_obj.text)\n",
    "                else:\n",
    "                    part_obj = objURI\n",
    "\n",
    "                r1 = ComponentQuery1(part_subj, part_pred, part_obj)\n",
    "                #print(r1)\n",
    "                if r1 and len(r1)>0:\n",
    "                    r2 = ComponentQuery2(part_subj, part_pred, part_obj)\n",
    "                    r2Result = False\n",
    "                    for group in r2:\n",
    "                        for result in group[\"results\"][\"bindings\"]:\n",
    "                            if len(result) > 0:\n",
    "                                r2Result = True\n",
    "                    if r2Result:\n",
    "                        r3 = ComponentQuery3(part_subj, part_pred, part_obj)\n",
    "                        if r3:\n",
    "                            print(\"\\nFind triple with 3 partial components:\")\n",
    "                            print(part_subj + \" - \" + part_pred + \" - \" + part_obj)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"\\nFind triple with 2 partial components\")\n",
    "                            PrintQueryResult(r2, part_subj, part_pred, part_obj)\n",
    "                            #print(r2)\n",
    "                    else:\n",
    "                        print(\"\\nFind single partial component(s):\")\n",
    "                        if part_subj != None:\n",
    "                            print(part_subj[1:len(part_subj)-1])\n",
    "                        if part_pred != None:\n",
    "                            print(part_pred[1:len(part_pred)-1])\n",
    "                        if part_obj != None:\n",
    "                            print(part_obj[1:len(part_obj)-1])\n",
    "                        PrintQueryResult(r1, part_subj, part_pred, part_obj)\n",
    "    \n",
    "    return True\n",
    "    #return len(r1)>0 or r2Result or r3\n",
    "\n",
    "# given a URI, query the ontology iteratively to get its path to root\n",
    "def QueryHierarchy(URI):\n",
    "    path = []\n",
    "    path.insert(0, URI)\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    curURI = URI\n",
    "    predicate = \"rdf:type\"\n",
    "    endFlag = False # to mark whether a dbo:entity is found in current level\n",
    "    \n",
    "    while not endFlag:\n",
    "        endFlag = True;\n",
    "        \n",
    "        qSelect = \"\"\"\n",
    "            SELECT ?type WHERE \n",
    "            {\n",
    "            \"\"\" + curURI + predicate + \"\"\" ?type.\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(qSelect)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            resultURI = '<' + result[\"type\"][\"value\"] + '>'\n",
    "            # begin the class part\n",
    "            if \"owl#Class\" in resultURI:\n",
    "                endFlag = False;\n",
    "                predicate = \"rdfs:subClassOf\"\n",
    "                break;\n",
    "            # insert the first found dbo:entity into the path\n",
    "            elif \"http://dbpedia.org/ontology\" in resultURI:\n",
    "                endFlag = False;\n",
    "                curURI = resultURI\n",
    "                path.insert(0, resultURI)\n",
    "                break;\n",
    "     \n",
    "    # insert the common root node to current path\n",
    "    path.insert(0, '<http://www.w3.org/2002/07/owl#Thing>')\n",
    "    return path\n",
    "            \n",
    "# get ontology hierarchy for every keyword and append the knowledge tree\n",
    "def AppendTree(URIList, treeDict):\n",
    "    for URI in URIList:\n",
    "        hierarchy = QueryHierarchy(URI);\n",
    "        #print(hierarchy)\n",
    "        \n",
    "        curDict = treeDict;\n",
    "        for curKey in hierarchy:\n",
    "            if curKey in curDict:\n",
    "                curDict = curDict[curKey]\n",
    "            else:\n",
    "                curDict[curKey] = dict()\n",
    "                curDict = curDict[curKey]\n",
    "                \n",
    "def QueryInfo(URI, entityInfo):\n",
    "    #sparql = SPARQLWrapper(\"dbpedia.owl\")\n",
    "    sparql.setQuery(\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        SELECT ?abstract ?thumb\n",
    "        WHERE {\"\"\" \n",
    "            + URI + \"\"\" dbo:abstract ?abstract .\"\"\"\n",
    "            + URI + \"\"\" dbo:thumbnail ?thumb .\n",
    "        FILTER (lang(?abstract) = 'en')\n",
    "        }\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        entityInfo[\"abstract\"] = result[\"abstract\"][\"value\"]\n",
    "        entityInfo[\"thumbnail\"] = result[\"thumb\"][\"value\"]\n",
    "    \n",
    "# A recursive helper function to traverse treeDict and format it to json\n",
    "def PreorderFormat(curDict):\n",
    "    if len(curDict) == 0:\n",
    "        return;\n",
    "    \n",
    "    childList = []\n",
    "    for key in curDict:\n",
    "        children = PreorderFormat(curDict[key])\n",
    "        if children:\n",
    "            childList.append({\n",
    "                \"name\": key,\n",
    "                \"children\": children\n",
    "            })\n",
    "        else:\n",
    "            childList.append({\n",
    "                \"name\": key\n",
    "            })\n",
    "    return childList\n",
    "    \n",
    "        \n",
    "def FormatToJson(treeDict):\n",
    "    result = PreorderFormat(treeDict)\n",
    "    finalResult = None\n",
    "    if result:\n",
    "        finalResult = {\n",
    "            \"name\": \"GroundRoot\",\n",
    "            \"children\": result\n",
    "        }\n",
    "    return finalResult\n",
    "\n",
    "def PrintQueryResult(results, sub, pred, obj):\n",
    "    # for sparqlWrapper\n",
    "    for group in results:\n",
    "        #print(group)\n",
    "        for result in group[\"results\"][\"bindings\"]:\n",
    "            print('( ', end='')\n",
    "            if \"sub\" in result:\n",
    "                print(NameURI(result[\"sub\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in sub:\n",
    "                    sub = sub[29:-1]\n",
    "                print(sub + ' -', end='')\n",
    "            if \"pred\" in result:\n",
    "                print(NameURI(result[\"pred\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in pred:\n",
    "                    pred = pred[29:-1]\n",
    "                print(pred + ' -', end='')\n",
    "            if \"obj\" in result:\n",
    "                print(NameURI(result[\"obj\"][\"value\"]) + ' )\\n', end='')\n",
    "            else:\n",
    "                if '<' in obj:\n",
    "                    obj = obj[29:-1]\n",
    "                print(obj + ' )\\n', end='')\n",
    "        \n",
    "    '''# for owlready\n",
    "    for result in results:\n",
    "        for var in result.vars:\n",
    "            print(var.toPython())\n",
    "        for binding in result.bindings:\n",
    "            print(binding.toPython())'''\n",
    "    \n",
    "# extract one triple from given sentence\n",
    "def RunNER(sen):\n",
    "    # initialize the named entity list\n",
    "    entityList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "\n",
    "    #ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if \"subj\" in chunk.root.dep_ or \"obj\" in chunk.root.dep_:\n",
    "            # test whether current chunk is or contains stop words\n",
    "            result = ''\n",
    "            doc_phrase = nlp(chunk.text)\n",
    "            for token in doc_phrase:\n",
    "                #print(token.text, token.is_stop, token.lemma_)\n",
    "                if not token.is_stop and token.lemma_ != \"-PRON-\":\n",
    "                # exclude stop words and personal pronouns (whose lemma_ is \"-PRON-\")\n",
    "                    result = result + token.text + ' '\n",
    "            \n",
    "            if result != '':\n",
    "                chunks.append(result[:-1])\n",
    "    \n",
    "    return chunks\n",
    "        \n",
    "# load Spacy NLP dictionary\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load DBPD ontology and construct graph for query\n",
    "#m_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "#m_onto = m_world.get_ontology(\"dbpedia.owl\").load()\n",
    "#m_graph = m_world.as_rdflib_graph()\n",
    "sparql = SPARQLWrapper(\"http://localhost:8890/sparql\")\n",
    "#sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "# load data\n",
    "file = open(\"shortdataset.csv\", \"r\")\n",
    "#file = open(\"newdataset_formatted.csv\", \"r\")\n",
    "reader = csv.reader(file)\n",
    "senSet = []\n",
    "for item in reader:\n",
    "    # format sentences in item as string\n",
    "    fullP = \"\".join(item)\n",
    "    splitP = fullP.split(\";\", 3);\n",
    "    splitS = splitP[3][1:len(splitP[3])].split(\".\");\n",
    "    #print(splitS)\n",
    "    for sen in splitS:\n",
    "        senSet.append(sen)#store the sentence into an array\n",
    "file.close()\n",
    "print(\"Total sentences: \" + str(len(senSet)))\n",
    "\n",
    "# pre-processing\n",
    "PreProcess(senSet)\n",
    "\n",
    "treeDict = dict()\n",
    "cacheDict = dict()\n",
    "# parse and query each sentence\n",
    "entityList = []\n",
    "#for index in range(10, 20):\n",
    "#for index in range(len(senSet)):\n",
    "index = 26\n",
    "#sampleSentence = \"Do you remember the administrator of this computer?\"\n",
    "sampleSentence = \"Neverland has the tree house.\"\n",
    "\n",
    "# extract named entities from current sentence\n",
    "entityList = RunNER(sampleSentence)\n",
    "#entityList = RunNER(senSet[index])\n",
    "print(entityList)\n",
    "\n",
    "# look up the URI for the entities\n",
    "URIList = []\n",
    "for entity in entityList:\n",
    "    print(\"\\nFor \\\"\" + entity + \"\\\":\")\n",
    "    try:\n",
    "        if entity in cacheDict:\n",
    "            entityURI = cacheDict[entity];\n",
    "            if entityURI != None: \n",
    "                print(\"You mentioned\", entity, \"before. Do you mean\", entityURI, \"?\")\n",
    "            else:\n",
    "                print(\"You mentioned\", entity, \"before, but we can't find anything about it.\")\n",
    "\n",
    "        else:\n",
    "            entityURI = QueryURI(entity)\n",
    "            cacheDict[entity] = entityURI\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #print(\"URI: \" + entityURI[1:len(entityURI)-1])\n",
    "        if entityURI != None:\n",
    "            URIList.append(entityURI)\n",
    "    except:\n",
    "        print(\"none\")\n",
    "\n",
    "print(URIList)\n",
    "\n",
    "'''if len(URIList)>0:\n",
    "    AppendTree(URIList, treeDict)'''\n",
    "\n",
    "outputList = []\n",
    "if len(URIList)>0:\n",
    "    for URI in URIList:\n",
    "        entityInfo = {\n",
    "            \"uri\": URI,\n",
    "            \"strPath\": \"\",\n",
    "            \"sentence\": senSet[index],\n",
    "            \"abstract\": None,\n",
    "            \"thumbnail\": None\n",
    "        }\n",
    "        hierarchy = QueryHierarchy(URI)\n",
    "        for curKey in hierarchy:\n",
    "            entityInfo[\"strPath\"] = entityInfo[\"strPath\"]  + curKey + \"&-&\"\n",
    "        entityInfo[\"strPath\"] = entityInfo[\"strPath\"][:-3]\n",
    "        QueryInfo(URI, entityInfo)\n",
    "        outputList.append(entityInfo)\n",
    "\n",
    "print(outputList)\n",
    "\n",
    "'''treeJson = FormatToJson(outputList)\n",
    "print(treeJson)\n",
    "\n",
    "with open('../IdeaTest/Tree/conv-test.json', 'w') as outfile:  \n",
    "    json.dump(treeJson, outfile, indent = 2)'''\n",
    "    \n",
    "\n",
    "'''subj = \"province link\"\n",
    "if pred == \"be\":\n",
    "    pred = \"type\"\n",
    "#obj = \"person\"\n",
    "\n",
    "# look up the URI for subj, pred and obj\n",
    "print(\"\\nFor subject \\\"\" + subj + \"\\\":\")\n",
    "subjURI = QueryURI(subj)\n",
    "print(\"\\nFor predicate \\\"\" + pred + \"\\\":\")\n",
    "predURI = QueryURI(pred)\n",
    "print(\"\\nFor object \\\"\" + obj + \"\\\":\")\n",
    "objURI = QueryURI(obj)\n",
    "\n",
    "try:\n",
    "    print(\"\\n\")\n",
    "    print(\"subject: \" + subjURI[1:len(subjURI)-1])\n",
    "    print(\"predicate: \" + predURI[1:len(predURI)-1])\n",
    "    print(\"object: \" + objURI[1:len(objURI)-1])\n",
    "except:\n",
    "    print(\"none\")\n",
    "    \n",
    "# query the triple in dbpd with SPARQL\n",
    "# queryResult = QueryTriple(subj, pred, obj)\n",
    "# print('Triple Query Result: ' + str(queryResult))\n",
    "\n",
    "# query the triple with several different methods\n",
    "r3 = ComponentQuery3(subjURI, predURI, objURI)\n",
    "if r3:\n",
    "    print(\"\\nFind origin component:\")\n",
    "    print(subj + ' - ' + pred + ' - ' + obj)\n",
    "else:\n",
    "    r2 = ComponentQuery2(subjURI, predURI, objURI)\n",
    "    if r2 and len(r2)>0:\n",
    "        print(\"\\nFind 2 components:\")\n",
    "        PrintQueryResult(r2, subj, pred, obj)#print(r2) \n",
    "    else:\n",
    "        r1 = ComponentQuery1(subjURI, predURI, objURI)\n",
    "        if r1 and len(r1)>0:\n",
    "            print(\"\\nFind single component(s):\")\n",
    "            if subjURI != None:\n",
    "                print(subjURI[1:len(subjURI)-1])\n",
    "            if predURI != None:\n",
    "                print(predURI[1:len(predURI)-1])\n",
    "            if objURI != None:\n",
    "                print(objURI[1:len(objURI)-1])\n",
    "            PrintQueryResult(r1, subj, pred, obj)#print(r1) \n",
    "    \n",
    "    #partial query\n",
    "    result = PartialQuery(subj, pred, obj, subjURI, predURI, objURI)\n",
    "    if not result:\n",
    "        print (\"Find nothing in parial query\")'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to remove WARNINGs from Owlready2\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31050\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "DESCRIBE not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b27ce1a90687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m DESCRIBE ?sub WHERE {\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m?\u001b[0m\u001b[0msub\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m  \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvince\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m }\"\"\"))\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         return result(processor.query(\n\u001b[0;32m-> 1089\u001b[0;31m             query_object, initBindings, initNs, **kwargs))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     def update(self, update_object, processor='sparql',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/processor.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrOrQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevalQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitBindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalQuery\u001b[0;34m(graph, query, initBindings, base)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevalPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalPart\u001b[0;34m(ctx, part)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DescribeQuery'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DESCRIBE not implemented'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: DESCRIBE not implemented"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Root Level', 'children': [{'name': 'Top Level', 'children': [{'name': 'TestTTTTT', 'children': [{'name': 'Child1 of A'}, {'name': 'Child2 of A', 'children': [{'name': 'Child1 of Child2'}, {'name': 'Child2 of Child2'}, {'name': 'Child3 of Child2'}]}, {'name': 'Child3 of A'}, {'name': 'Child4 of A'}, {'name': 'Child5 of A'}]}, {'name': 'Level 2: B', 'children': [{'name': 'Child1 of B'}, {'name': 'Child2 of B'}, {'name': 'Child3 of B'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    \"name\": \"Root Level\",\n",
    "    \"children\": [{ \n",
    "        \"name\": \"Top Level\",\n",
    "        \"children\": [{ \n",
    "            \"name\": \"Level 2: A\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of A\" },\n",
    "                    { \"name\": \"Child2 of A\",\n",
    "                        \"children\": [\n",
    "                            { \"name\": \"Child1 of Child2\" },\n",
    "                            { \"name\": \"Child2 of Child2\" },\n",
    "                            { \"name\": \"Child3 of Child2\" }\n",
    "                        ]\n",
    "                    },\n",
    "                    { \"name\": \"Child3 of A\" },\n",
    "                    { \"name\": \"Child4 of A\" },\n",
    "                    { \"name\": \"Child5 of A\" }\n",
    "                ]\n",
    "            },\n",
    "            { \n",
    "                \"name\": \"Level 2: B\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of B\" },\n",
    "                    { \"name\": \"Child2 of B\" },\n",
    "                    { \"name\": \"Child3 of B\" }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "}\n",
    "\n",
    "# print(d)\n",
    "\n",
    "node = d[\"children\"][0][\"children\"][0]\n",
    "node[\"name\"] = \"TestTTTTT\"\n",
    "\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
