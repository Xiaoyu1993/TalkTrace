{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary created!\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary based on all the words in the ontology\n",
    "\n",
    "import csv\n",
    "\n",
    "# load from original dataset\n",
    "with open('CSO.3.1_short.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    entitySet = set()\n",
    "    for item in reader:\n",
    "        # subject\n",
    "        if \"https://cso.kmi.open.ac.uk/topics/\" in item[0]:\n",
    "            entity = item[0].replace('https://cso.kmi.open.ac.uk/topics/', '')\n",
    "            entitySet.add(entity[1:-1])\n",
    "        \n",
    "        # object\n",
    "        if \"https://cso.kmi.open.ac.uk/topics/\" in item[2]:\n",
    "            entity = item[2].replace('https://cso.kmi.open.ac.uk/topics/', '')\n",
    "            entitySet.add(entity[1:-1])\n",
    "    #print (entitySet)\n",
    "\n",
    "# store to new dictionary\n",
    "with open('cso_dict_short.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for entity in entitySet:\n",
    "        writer.writerow({entity})\n",
    "\n",
    "print (\"Dictionary created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query local ontology ('nt' format) with \n",
    "from rdflib import Graph\n",
    "import json\n",
    "\n",
    "g = Graph()\n",
    "#g.parse(\"CSO.3.1.nt\", format=\"nt\")\n",
    "g.parse(\"dbpedia.nt\", format=\"nt\")\n",
    "\n",
    "results = g.query(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?label\n",
    "    WHERE { <https://cso.kmi.open.ac.uk/topics/robotics> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?label }\n",
    "\"\"\").serialize(format=\"json\")\n",
    "results = json.loads(results)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"label\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cso.kmi.open.ac.uk/schema/cso#Topic\n"
     ]
    }
   ],
   "source": [
    "# query online ontology ('owl' format) with sparqlWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "#sparql = SPARQLWrapper(\"dbpedia.owl\")\n",
    "sparql = SPARQLWrapper(\"http://localhost:8890/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?label\n",
    "    WHERE { <https://cso.kmi.open.ac.uk/topics/robotics> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?label }\n",
    "\"\"\")\n",
    "# SELECT * WHERE {\n",
    "#        ?s ?p ?o .\n",
    "#}\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"label\"][\"value\"])\n",
    "    #print(result[\"thumb\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "\n",
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# load from original dataset\n",
    "with open('CSO.3.1_short.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    entitySet = set()\n",
    "    for item in reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 46\n",
      "Pre-processing...\n",
      "\n",
      "26. Original Sentence:\n",
      "We examine how animating a viewpoint change in a spatial information system affects a user’s ability to build a mental map of the information in the space. We found that animation improves users' ability to reconstruct the information space, with no penalty on task performance time. We believe that this study provides strong evidence for adding animated transitions in many applications with fixed spatial data where the user navigates around the data space.\n",
      "['viewpoint change', 'spatial information system', 'user ’s ability', 'mental map', 'information', 'space', 'animation', \"users ' ability\", 'information space', 'penalty', 'task performance time', 'study', 'strong evidence', 'animated transitions', 'applications', 'fixed spatial data', 'user', 'data space']\n",
      "\n",
      "For \"viewpoint change\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"spatial information system\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"user ’s ability\":\n",
      "none\n",
      "\n",
      "For \"mental map\":\n",
      "['http://dbpedia.org/resource/Cognitive_map', 'http://dbpedia.org/resource/Mental_mapping']\n",
      "\n",
      "\n",
      "\n",
      "For \"information\":\n",
      "['http://dbpedia.org/resource/Information_technology', 'http://dbpedia.org/resource/Statistics', 'http://dbpedia.org/resource/Talk_radio', 'http://dbpedia.org/resource/Public_relations', 'http://dbpedia.org/resource/Database']\n",
      "\n",
      "\n",
      "\n",
      "For \"space\":\n",
      "['http://dbpedia.org/resource/NASA', 'http://dbpedia.org/resource/Myspace', 'http://dbpedia.org/resource/Area', 'http://dbpedia.org/resource/Satellite', 'http://dbpedia.org/resource/Geography']\n",
      "\n",
      "\n",
      "\n",
      "For \"animation\":\n",
      "['http://dbpedia.org/resource/Anime', 'http://dbpedia.org/resource/Animation', 'http://dbpedia.org/resource/3D_computer_graphics', 'http://dbpedia.org/resource/Computer-generated_imagery', 'http://dbpedia.org/resource/Original_video_animation']\n",
      "\n",
      "\n",
      "\n",
      "For \"users ' ability\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"information space\":\n",
      "['http://dbpedia.org/resource/Information_warfare', 'http://dbpedia.org/resource/Information_space_analysis', 'http://dbpedia.org/resource/Information_space']\n",
      "\n",
      "\n",
      "\n",
      "For \"penalty\":\n",
      "['http://dbpedia.org/resource/Capital_punishment', 'http://dbpedia.org/resource/Penalty_shoot-out_(association_football)', 'http://dbpedia.org/resource/Penalty_kick', 'http://dbpedia.org/resource/LGBT_rights_by_country_or_territory', 'http://dbpedia.org/resource/Execution_by_firing_squad']\n",
      "\n",
      "\n",
      "\n",
      "For \"task performance time\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"study\":\n",
      "['http://dbpedia.org/resource/Science', 'http://dbpedia.org/resource/Management', 'http://dbpedia.org/resource/Research', 'http://dbpedia.org/resource/Entomology', 'http://dbpedia.org/resource/Postgraduate_education']\n",
      "\n",
      "\n",
      "\n",
      "For \"strong evidence\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"animated transitions\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"applications\":\n",
      "['http://dbpedia.org/resource/Software', 'http://dbpedia.org/resource/Application_software', 'http://dbpedia.org/resource/Graphical_user_interface', 'http://dbpedia.org/resource/Computer_program', 'http://dbpedia.org/resource/.NET_Framework']\n",
      "\n",
      "\n",
      "\n",
      "For \"fixed spatial data\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "For \"user\":\n",
      "['http://dbpedia.org/resource/Graphical_user_interface', 'http://dbpedia.org/resource/Substance_abuse', 'http://dbpedia.org/resource/User_interface', 'http://dbpedia.org/resource/Limited-access_road', 'http://dbpedia.org/resource/Wheelchair']\n",
      "\n",
      "\n",
      "\n",
      "For \"data space\":\n",
      "['http://dbpedia.org/resource/Delimiter-separated_values', 'http://dbpedia.org/resource/Dataspaces', 'http://dbpedia.org/resource/Semantic_web_data_space']\n",
      "\n",
      "\n",
      "[['http://dbpedia.org/resource/Cognitive_map', 'http://dbpedia.org/resource/Mental_mapping'], ['http://dbpedia.org/resource/Information_technology', 'http://dbpedia.org/resource/Statistics', 'http://dbpedia.org/resource/Talk_radio', 'http://dbpedia.org/resource/Public_relations', 'http://dbpedia.org/resource/Database'], ['http://dbpedia.org/resource/NASA', 'http://dbpedia.org/resource/Myspace', 'http://dbpedia.org/resource/Area', 'http://dbpedia.org/resource/Satellite', 'http://dbpedia.org/resource/Geography'], ['http://dbpedia.org/resource/Anime', 'http://dbpedia.org/resource/Animation', 'http://dbpedia.org/resource/3D_computer_graphics', 'http://dbpedia.org/resource/Computer-generated_imagery', 'http://dbpedia.org/resource/Original_video_animation'], ['http://dbpedia.org/resource/Information_warfare', 'http://dbpedia.org/resource/Information_space_analysis', 'http://dbpedia.org/resource/Information_space'], ['http://dbpedia.org/resource/Capital_punishment', 'http://dbpedia.org/resource/Penalty_shoot-out_(association_football)', 'http://dbpedia.org/resource/Penalty_kick', 'http://dbpedia.org/resource/LGBT_rights_by_country_or_territory', 'http://dbpedia.org/resource/Execution_by_firing_squad'], ['http://dbpedia.org/resource/Science', 'http://dbpedia.org/resource/Management', 'http://dbpedia.org/resource/Research', 'http://dbpedia.org/resource/Entomology', 'http://dbpedia.org/resource/Postgraduate_education'], ['http://dbpedia.org/resource/Software', 'http://dbpedia.org/resource/Application_software', 'http://dbpedia.org/resource/Graphical_user_interface', 'http://dbpedia.org/resource/Computer_program', 'http://dbpedia.org/resource/.NET_Framework'], ['http://dbpedia.org/resource/Graphical_user_interface', 'http://dbpedia.org/resource/Substance_abuse', 'http://dbpedia.org/resource/User_interface', 'http://dbpedia.org/resource/Limited-access_road', 'http://dbpedia.org/resource/Wheelchair'], ['http://dbpedia.org/resource/Delimiter-separated_values', 'http://dbpedia.org/resource/Dataspaces', 'http://dbpedia.org/resource/Semantic_web_data_space']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-99d32313d887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;34m\"thumbnail\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         }\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryHierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurKey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"strPath\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mcurKey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&-&\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-99d32313d887>\u001b[0m in \u001b[0;36mQueryHierarchy\u001b[0;34m(URI)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mSELECT\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mWHERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             {\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;34m\"\"\" + curURI + predicate + \"\"\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             }\n\u001b[1;32m    141\u001b[0m         \"\"\"\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "import json\n",
    "\n",
    "import urllib\n",
    "#from owlready2 import *\n",
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from allennlp.common.testing import AllenNlpTestCase\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# pre-processing\n",
    "def PreProcess(senSet):\n",
    "    #remove content between [ ]\n",
    "    print(\"Pre-processing...\")\n",
    "    for index in range(len(senSet)):\n",
    "        while senSet[index].find('[')>=0:\n",
    "            i_start = senSet[index].find('[')\n",
    "            i_end = senSet[index].find(']')\n",
    "            s = senSet[index][i_start:i_end+2]\n",
    "            senSet[index] = senSet[index].replace(s, \"\")\n",
    "\n",
    "\n",
    "def QueryURI(keywords, index=-2):\n",
    "    localSite = 'http://localhost:1111/api/search/KeywordSearch?'\n",
    "    onlineSite = 'http://lookup.dbpedia.org/api/search/KeywordSearch?'\n",
    "    prefix = \"{http://lookup.dbpedia.org/}\"\n",
    "    \n",
    "    keywords = keywords.replace(' ', \"%20\")\n",
    "    request = onlineSite + \\\n",
    "    'QueryClass='   + ''  + \\\n",
    "    '&MaxHits='     + '5' + \\\n",
    "    '&QueryString=' + keywords\n",
    "    response = str(urllib.request.urlopen(request).read(), 'utf-8')\n",
    "\n",
    "    root = ET.fromstring(response)\n",
    "    result = root.findall(prefix + \"Result\")\n",
    "    uriList = []\n",
    "    \n",
    "    if len(result)>0:\n",
    "        for entity in result:\n",
    "            uriList.append(entity.find(prefix + \"URI\").text);\n",
    "        return uriList\n",
    "    else:\n",
    "        print(\"Sorry, we find nothing for this stuff :(\\n\")\n",
    "        return None\n",
    "    \n",
    "    '''if len(result)>0:\n",
    "        selected = -1\n",
    "        count = 0\n",
    "        for name in result:\n",
    "            print(str(count) + \": \" + name.find(prefix + \"Label\").text)\n",
    "            count += 1\n",
    "        # for some default input during debugging\n",
    "        if index<-1:\n",
    "            index = int(input(\"Which one is closer to what you mean? (type \\\"-1\\\" if nothing seems correct) \"))\n",
    "        if index >= 0:\n",
    "            selected = \"<\" + result[index].find(prefix + \"URI\").text + \">\"\n",
    "        else:\n",
    "            selected = None\n",
    "        return selected.replace(\"/resource\", \"/ontology\")\n",
    "    else:\n",
    "        print(\"Sorry, we find nothing for this stuff :(\\n\")\n",
    "        return None'''\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def FormatURI(phrase, isS_O = False):\n",
    "    #print('Before formatting:  ' + phrase)\n",
    "    chars = list(phrase)\n",
    "    \n",
    "    if len(chars) > 0 and not isS_O:\n",
    "        chars[0] = chars[0].upper()\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == ' ' and i+1 < len(chars):\n",
    "            chars[i+1] = chars[i+1].upper()\n",
    "    phrase = ''.join(chars)\n",
    "    phrase = phrase.replace(' ', '')\n",
    "    phrase = re.sub(r'[^a-zA-Z0-9\\s]', '', phrase)\n",
    "    #print('After formatting:  ' + phrase)\n",
    "    return phrase\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def NameURI(url):\n",
    "    index_slash = 0\n",
    "    for i in range(len(url)-1, -1, -1):\n",
    "        if url[i] == '/':\n",
    "            index_slash = i+1\n",
    "            break\n",
    "    return url[index_slash:]\n",
    "\n",
    "# query the given triple in the ontology with SPARQL\n",
    "# return true/false as result\n",
    "def QueryTriple(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"Province\"\n",
    "        qSelect = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "\n",
    "        r = list(m_graph.query(qAsk))\n",
    "        return r\n",
    "\n",
    "# given a URI, query the ontology iteratively to get its path to root\n",
    "def QueryHierarchy(URI):\n",
    "    path = []\n",
    "    path.insert(0, URI)\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    curURI = URI\n",
    "    predicate = \"rdf:type\"\n",
    "    endFlag = False # to mark whether a dbo:entity is found in current level\n",
    "    \n",
    "    while not endFlag:\n",
    "        endFlag = True;\n",
    "        \n",
    "        qSelect = \"\"\"\n",
    "            SELECT ?type WHERE \n",
    "            {\n",
    "            \"\"\" + curURI + predicate + \"\"\" ?type.\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(qSelect)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            resultURI = '<' + result[\"type\"][\"value\"] + '>'\n",
    "            # begin the class part\n",
    "            if \"owl#Class\" in resultURI:\n",
    "                endFlag = False;\n",
    "                predicate = \"rdfs:subClassOf\"\n",
    "                break;\n",
    "            # insert the first found dbo:entity into the path\n",
    "            elif \"http://dbpedia.org/ontology\" in resultURI:\n",
    "                endFlag = False;\n",
    "                curURI = resultURI\n",
    "                path.insert(0, resultURI)\n",
    "                break;\n",
    "     \n",
    "    # insert the common root node to current path\n",
    "    path.insert(0, '<http://www.w3.org/2002/07/owl#Thing>')\n",
    "    return path\n",
    "            \n",
    "# get ontology hierarchy for every keyword and append the knowledge tree\n",
    "def AppendTree(URIList, treeDict):\n",
    "    for URI in URIList:\n",
    "        hierarchy = QueryHierarchy(URI);\n",
    "        #print(hierarchy)\n",
    "        \n",
    "        curDict = treeDict;\n",
    "        for curKey in hierarchy:\n",
    "            if curKey in curDict:\n",
    "                curDict = curDict[curKey]\n",
    "            else:\n",
    "                curDict[curKey] = dict()\n",
    "                curDict = curDict[curKey]\n",
    "                \n",
    "def QueryInfo(URI, entityInfo):\n",
    "    #sparql = SPARQLWrapper(\"dbpedia.owl\")\n",
    "    sparql.setQuery(\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        SELECT ?abstract ?thumb\n",
    "        WHERE {\"\"\" \n",
    "            + URI + \"\"\" dbo:abstract ?abstract .\"\"\"\n",
    "            + URI + \"\"\" dbo:thumbnail ?thumb .\n",
    "        FILTER (lang(?abstract) = 'en')\n",
    "        }\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        entityInfo[\"abstract\"] = result[\"abstract\"][\"value\"]\n",
    "        entityInfo[\"thumbnail\"] = result[\"thumb\"][\"value\"]\n",
    "    \n",
    "# A recursive helper function to traverse treeDict and format it to json\n",
    "def PreorderFormat(curDict):\n",
    "    if len(curDict) == 0:\n",
    "        return;\n",
    "    \n",
    "    childList = []\n",
    "    for key in curDict:\n",
    "        children = PreorderFormat(curDict[key])\n",
    "        if children:\n",
    "            childList.append({\n",
    "                \"name\": key,\n",
    "                \"children\": children\n",
    "            })\n",
    "        else:\n",
    "            childList.append({\n",
    "                \"name\": key\n",
    "            })\n",
    "    return childList\n",
    "    \n",
    "        \n",
    "def FormatToJson(treeDict):\n",
    "    result = PreorderFormat(treeDict)\n",
    "    finalResult = None\n",
    "    if result:\n",
    "        finalResult = {\n",
    "            \"name\": \"GroundRoot\",\n",
    "            \"children\": result\n",
    "        }\n",
    "    return finalResult\n",
    "\n",
    "def PrintQueryResult(results, sub, pred, obj):\n",
    "    # for sparqlWrapper\n",
    "    for group in results:\n",
    "        #print(group)\n",
    "        for result in group[\"results\"][\"bindings\"]:\n",
    "            print('( ', end='')\n",
    "            if \"sub\" in result:\n",
    "                print(NameURI(result[\"sub\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in sub:\n",
    "                    sub = sub[29:-1]\n",
    "                print(sub + ' -', end='')\n",
    "            if \"pred\" in result:\n",
    "                print(NameURI(result[\"pred\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in pred:\n",
    "                    pred = pred[29:-1]\n",
    "                print(pred + ' -', end='')\n",
    "            if \"obj\" in result:\n",
    "                print(NameURI(result[\"obj\"][\"value\"]) + ' )\\n', end='')\n",
    "            else:\n",
    "                if '<' in obj:\n",
    "                    obj = obj[29:-1]\n",
    "                print(obj + ' )\\n', end='')\n",
    "        \n",
    "    '''# for owlready\n",
    "    for result in results:\n",
    "        for var in result.vars:\n",
    "            print(var.toPython())\n",
    "        for binding in result.bindings:\n",
    "            print(binding.toPython())'''\n",
    "    \n",
    "# extract one triple from given sentence\n",
    "def RunNER(sen):\n",
    "    # initialize the named entity list\n",
    "    entityList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "\n",
    "    #ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if \"subj\" in chunk.root.dep_ or \"obj\" in chunk.root.dep_:\n",
    "            # test whether current chunk is or contains stop words\n",
    "            result = ''\n",
    "            doc_phrase = nlp(chunk.text)\n",
    "            for token in doc_phrase:\n",
    "                #print(token.text, token.is_stop, token.lemma_)\n",
    "                if not token.is_stop and token.lemma_ != \"-PRON-\":\n",
    "                # exclude stop words and personal pronouns (whose lemma_ is \"-PRON-\")\n",
    "                    result = result + token.text + ' '\n",
    "            \n",
    "            if result != '':\n",
    "                chunks.append(result[:-1])\n",
    "    \n",
    "    return chunks\n",
    "        \n",
    "# load Spacy NLP dictionary\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load DBPD ontology and construct graph for query\n",
    "#m_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "#m_onto = m_world.get_ontology(\"dbpedia.owl\").load()\n",
    "#m_graph = m_world.as_rdflib_graph()\n",
    "sparql = SPARQLWrapper(\"http://localhost:8890/sparql\")\n",
    "#sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "# load data\n",
    "file = open(\"shortdataset.csv\", \"r\")\n",
    "#file = open(\"newdataset_formatted.csv\", \"r\")\n",
    "reader = csv.reader(file)\n",
    "senSet = []\n",
    "for item in reader:\n",
    "    # format sentences in item as string\n",
    "    fullP = \"\".join(item)\n",
    "    splitP = fullP.split(\";\", 3);\n",
    "    splitS = splitP[3][1:len(splitP[3])].split(\".\");\n",
    "    #print(splitS)\n",
    "    for sen in splitS:\n",
    "        senSet.append(sen)#store the sentence into an array\n",
    "file.close()\n",
    "print(\"Total sentences: \" + str(len(senSet)))\n",
    "\n",
    "# pre-processing\n",
    "PreProcess(senSet)\n",
    "\n",
    "treeDict = dict()\n",
    "cacheDict = dict()\n",
    "# parse and query each sentence\n",
    "entityList = []\n",
    "#for index in range(10, 20):\n",
    "#for index in range(len(senSet)):\n",
    "index = 26\n",
    "sampleSentence = \"We examine how animating a viewpoint change in a spatial \\\n",
    "information system affects a user’s ability to build a mental \\\n",
    "map of the information in the space. We found that \\\n",
    "animation improves users' ability to reconstruct the \\\n",
    "information space, with no penalty on task performance \\\n",
    "time. We believe that this study provides strong evidence \\\n",
    "for adding animated transitions in many applications with \\\n",
    "fixed spatial data where the user navigates around the data \\\n",
    "space.\"\n",
    "# sampleSentence = \"Neverland has the tree house.\"\n",
    "\n",
    "# extract named entities from current sentence\n",
    "entityList = RunNER(sampleSentence)\n",
    "#entityList = RunNER(senSet[index])\n",
    "print(entityList)\n",
    "\n",
    "# look up the URI for the entities\n",
    "URIList = []\n",
    "for entity in entityList:\n",
    "    print(\"\\nFor \\\"\" + entity + \"\\\":\")\n",
    "    try:\n",
    "        if entity in cacheDict:\n",
    "            entityURI = cacheDict[entity];\n",
    "            if entityURI != None: \n",
    "                print(\"You mentioned\", entity, \"before. Do you mean\", entityURI, \"?\")\n",
    "            else:\n",
    "                print(\"You mentioned\", entity, \"before, but we can't find anything about it.\")\n",
    "\n",
    "        else:\n",
    "            entityURI = QueryURI(entity)\n",
    "            print(entityURI)\n",
    "            #cacheDict[entity] = entityURI\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #print(\"URI: \" + entityURI[1:len(entityURI)-1])\n",
    "        if entityURI != None:\n",
    "            #URIList.append(entityURI)\n",
    "            for dbpediaURI in entityURI:\n",
    "                csoURIs = DBPD2CSO(dbpediaURI)\n",
    "                URIList.extend(csoURIs)\n",
    "    except:\n",
    "        print(\"none\")\n",
    "\n",
    "print(URIList)\n",
    "\n",
    "'''if len(URIList)>0:\n",
    "    AppendTree(URIList, treeDict)'''\n",
    "\n",
    "outputList = []\n",
    "if len(URIList)>0:\n",
    "    for URI in URIList:\n",
    "        entityInfo = {\n",
    "            \"uri\": URI,\n",
    "            \"strPath\": \"\",\n",
    "            \"sentence\": senSet[index],\n",
    "            \"abstract\": None,\n",
    "            \"thumbnail\": None\n",
    "        }\n",
    "        hierarchy = QueryHierarchy(URI)\n",
    "        for curKey in hierarchy:\n",
    "            entityInfo[\"strPath\"] = entityInfo[\"strPath\"]  + curKey + \"&-&\"\n",
    "        entityInfo[\"strPath\"] = entityInfo[\"strPath\"][:-3]\n",
    "        QueryInfo(URI, entityInfo)\n",
    "        outputList.append(entityInfo)\n",
    "\n",
    "print(outputList)\n",
    "\n",
    "'''treeJson = FormatToJson(outputList)\n",
    "print(treeJson)\n",
    "\n",
    "with open('../IdeaTest/Tree/conv-test.json', 'w') as outfile:  \n",
    "    json.dump(treeJson, outfile, indent = 2)'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to remove WARNINGs from Owlready2\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31050\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "DESCRIBE not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b27ce1a90687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m DESCRIBE ?sub WHERE {\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m?\u001b[0m\u001b[0msub\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m  \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvince\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m }\"\"\"))\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         return result(processor.query(\n\u001b[0;32m-> 1089\u001b[0;31m             query_object, initBindings, initNs, **kwargs))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     def update(self, update_object, processor='sparql',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/processor.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrOrQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevalQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitBindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalQuery\u001b[0;34m(graph, query, initBindings, base)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevalPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalPart\u001b[0;34m(ctx, part)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DescribeQuery'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DESCRIBE not implemented'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: DESCRIBE not implemented"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Root Level', 'children': [{'name': 'Top Level', 'children': [{'name': 'TestTTTTT', 'children': [{'name': 'Child1 of A'}, {'name': 'Child2 of A', 'children': [{'name': 'Child1 of Child2'}, {'name': 'Child2 of Child2'}, {'name': 'Child3 of Child2'}]}, {'name': 'Child3 of A'}, {'name': 'Child4 of A'}, {'name': 'Child5 of A'}]}, {'name': 'Level 2: B', 'children': [{'name': 'Child1 of B'}, {'name': 'Child2 of B'}, {'name': 'Child3 of B'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    \"name\": \"Root Level\",\n",
    "    \"children\": [{ \n",
    "        \"name\": \"Top Level\",\n",
    "        \"children\": [{ \n",
    "            \"name\": \"Level 2: A\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of A\" },\n",
    "                    { \"name\": \"Child2 of A\",\n",
    "                        \"children\": [\n",
    "                            { \"name\": \"Child1 of Child2\" },\n",
    "                            { \"name\": \"Child2 of Child2\" },\n",
    "                            { \"name\": \"Child3 of Child2\" }\n",
    "                        ]\n",
    "                    },\n",
    "                    { \"name\": \"Child3 of A\" },\n",
    "                    { \"name\": \"Child4 of A\" },\n",
    "                    { \"name\": \"Child5 of A\" }\n",
    "                ]\n",
    "            },\n",
    "            { \n",
    "                \"name\": \"Level 2: B\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of B\" },\n",
    "                    { \"name\": \"Child2 of B\" },\n",
    "                    { \"name\": \"Child3 of B\" }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "}\n",
    "\n",
    "# print(d)\n",
    "\n",
    "node = d[\"children\"][0][\"children\"][0]\n",
    "node[\"name\"] = \"TestTTTTT\"\n",
    "\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
