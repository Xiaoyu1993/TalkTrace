{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/2002/07/owl#Thing\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    SELECT ?type WHERE \n",
    "    { \n",
    "      # give me ?type of the resource\n",
    "       <http://dbpedia.org/resource/Landscape_architecture> rdf:type ?type.\n",
    "\n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"type\"][\"value\"])\n",
    "    #print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 46\n",
      "Pre-processing...\n",
      "\n",
      "10. Original Sentence:\n",
      "  It varies here\n",
      "      SPACE _SP     False False\n",
      "It -PRON- PRON PRP ROOT Xx True False\n",
      "['   ']\n",
      "\n",
      "For \"   \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "11. Original Sentence:\n",
      "  Um camp location and we want to feel like we are in the woods\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "woods wood NOUN NNS ROOT xxxx True False\n",
      "['woods ']\n",
      "\n",
      "For \"woods \":\n",
      "0: Forest\n",
      "1: Wood\n",
      "2: Woodland\n",
      "3: Beech\n",
      "4: Tiger Woods\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Forest>']\n",
      "\n",
      "12. Original Sentence:\n",
      "  Um we construct things differently here\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "things thing NOUN NNS ROOT xxxx True False\n",
      "['things ']\n",
      "\n",
      "For \"things \":\n",
      "0: Organism\n",
      "1: Flag of the United States\n",
      "2: Sin\n",
      "3: Dharma\n",
      "4: Smallville\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "13. Original Sentence:\n",
      "  Um tree protection is critically important to us um in whatever we're doing on any of our campuses but especially here in the woods\n",
      "tree tree NOUN NN compound xxxx True False\n",
      "protection protection NOUN NN ROOT xxxx True False\n",
      "us -PRON- PRON PRP ROOT xx True True\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "our -PRON- ADJ PRP$ poss xxx True True\n",
      "campuses campus NOUN NNS ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "woods wood NOUN NNS ROOT xxxx True False\n",
      "['tree protection ', 'campuses ', 'woods ']\n",
      "\n",
      "For \"tree protection \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"campuses \":\n",
      "0: Higher education\n",
      "1: Campus\n",
      "2: Historically black colleges and universities\n",
      "3: Continuing education\n",
      "4: University of Wisconsin System\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "\n",
      "For \"woods \":\n",
      "0: Forest\n",
      "1: Wood\n",
      "2: Woodland\n",
      "3: Beech\n",
      "4: Tiger Woods\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Campus>', '<http://dbpedia.org/resource/Forest>']\n",
      "\n",
      "14. Original Sentence:\n",
      "  Um we're very selective about tree removal\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "tree tree NOUN NN compound xxxx True False\n",
      "removal removal NOUN NN ROOT xxxx True False\n",
      "['tree removal ']\n",
      "\n",
      "For \"tree removal \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "15. Original Sentence:\n",
      "  Um so just a minute ago we were talking about selectively removing some trees um that would be very selectively   we wouldn't think - have too much reservation about removing ah -\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "some some DET DT det xxxx True True\n",
      "trees tree NOUN NNS ROOT xxxx True False\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "too too ADV RB advmod xxx True True\n",
      "much much ADJ JJ amod xxxx True True\n",
      "reservation reservation NOUN NN ROOT xxxx True False\n",
      "['trees ', 'reservation ']\n",
      "\n",
      "For \"trees \":\n",
      "0: Oak\n",
      "1: Tree\n",
      "2: Pine\n",
      "3: Phylogenetics\n",
      "4: Deciduous\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "\n",
      "For \"reservation \":\n",
      "0: The Pentagon\n",
      "1: Right-of-way (transportation)\n",
      "2: Indian reservation\n",
      "3: Guantanamo Bay Naval Base\n",
      "4: Choctaw\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Tree>']\n",
      "\n",
      "16. Original Sentence:\n",
      "undergrowth   some scrub growth at this time of year especially if it blocks your views down to the water flow\n",
      "some some DET DT det xxxx True True\n",
      "scrub scrub NOUN NN amod xxxx True False\n",
      "growth growth NOUN NN ROOT xxxx True False\n",
      "this this DET DT det xxxx True True\n",
      "time time NOUN NN ROOT xxxx True False\n",
      "year year NOUN NN ROOT xxxx True False\n",
      "it -PRON- PRON PRP ROOT xx True True\n",
      "your -PRON- ADJ PRP$ poss xxxx True True\n",
      "views view NOUN NNS ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "water water NOUN NN compound xxxx True False\n",
      "flow flow NOUN NN ROOT xxxx True False\n",
      "['scrub growth ', 'time ', 'year ', 'views ', 'water flow ']\n",
      "\n",
      "For \"scrub growth \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"time \":\n",
      "0: Time (magazine)\n",
      "1: Coordinated Universal Time\n",
      "2: Eastern Time Zone (North America)\n",
      "3: French Revolutionary Wars\n",
      "4: Overtime (sports)\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"year \":\n",
      "0: Light-year\n",
      "1: 2010 FIFA World Cup\n",
      "2: 2007â€“2012 global financial crisis\n",
      "3: 2002 FIFA World Cup\n",
      "4: Lists of state leaders by year\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"views \":\n",
      "0: Pay-per-view\n",
      "1: Landscape art\n",
      "2: Ideology\n",
      "3: Televisa\n",
      "4: Eugenics\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"water flow \":\n",
      "0: Fluid dynamics\n",
      "1: Volumetric flow rate\n",
      "2: Hydrological transport model\n",
      "3: Stream gradient\n",
      "4: Baseflow\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Volumetric_flow_rate>']\n",
      "\n",
      "17. Original Sentence:\n",
      "  But we start talking about 10- 12- and 30-inch trees\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "[]\n",
      "[]\n",
      "\n",
      "18. Original Sentence:\n",
      " um probably gonna look to another solution and find a better better place where we can get a view\n",
      "another another DET DT det xxxx True True\n",
      "solution solution NOUN NN ROOT xxxx True False\n",
      "a a DET DT det x True True\n",
      "better better ADV RBR advmod xxxx True False\n",
      "better good ADJ JJR amod xxxx True False\n",
      "place place NOUN NN ROOT xxxx True False\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "a a DET DT det x True True\n",
      "view view NOUN NN ROOT xxxx True False\n",
      "['solution ', 'better better place ', 'view ']\n",
      "\n",
      "For \"solution \":\n",
      "0: Solution\n",
      "1: Vector space\n",
      "2: Electronic commerce\n",
      "3: Hydrochloric acid\n",
      "4: Starch\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "\n",
      "For \"better better place \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"view \":\n",
      "0: Pay-per-view\n",
      "1: First-person shooter\n",
      "2: Council of Trent\n",
      "3: Action game\n",
      "4: Secularism\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Solution>']\n",
      "\n",
      "19. Original Sentence:\n",
      "  Um but I will say um there are really striking views there and there are some great possibilities there that give the sense of almost ah an overlook similar to some of these others that you have up on the bluff\n",
      "I -PRON- PRON PRP ROOT X True False\n",
      "um um INTJ UH intj xx True False\n",
      "there there ADV EX expl xxxx True True\n",
      "are be VERB VBP ROOT xxx True True\n",
      "really really ADV RB advmod xxxx True True\n",
      "striking striking ADJ JJ amod xxxx True False\n",
      "views view NOUN NNS attr xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "sense sense NOUN NN ROOT xxxx True False\n",
      "an an DET DT det xx True True\n",
      "overlook overlook NOUN NN ROOT xxxx True False\n",
      "these these DET DT det xxxx True True\n",
      "others other NOUN NNS ROOT xxxx True True\n",
      "you -PRON- PRON PRP ROOT xxx True True\n",
      "the the DET DT det xxx True True\n",
      "bluff bluff NOUN NN ROOT xxxx True False\n",
      "['um striking views ', 'sense ', 'overlook ', 'bluff ']\n",
      "\n",
      "For \"um striking views \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"sense \":\n",
      "0: Fashion\n",
      "1: Black comedy\n",
      "2: Alternative medicine\n",
      "3: Tragedy\n",
      "4: Historical episcopate\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"overlook \":\n",
      "0: The Shining (novel)\n",
      "1: The Overlook Press\n",
      "2: Overlook, Portland, Oregon\n",
      "3: Historical buildings and structures of Zion National Park\n",
      "4: Overlook\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 4\n",
      "\n",
      "\n",
      "\n",
      "For \"bluff \":\n",
      "0: Hill\n",
      "1: Cliff\n",
      "2: Pine Bluff, Arkansas\n",
      "3: Parkland County, Alberta\n",
      "4: Deception\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Overlook>', '<http://dbpedia.org/resource/Cliff>']\n",
      "\n",
      "20. Original Sentence:\n",
      "  Um its its variance um with good design you may be able to integrate that with a resting interval uh get up halfway and then you push out um and then you go back up to go on up to what would be the the larger tree house space\n",
      "its -PRON- ADJ PRP$ poss xxx True True\n",
      "its -PRON- ADJ PRP$ poss xxx True True\n",
      "variance variance NOUN NN ROOT xxxx True False\n",
      "good good ADJ JJ amod xxxx True False\n",
      "design design NOUN NN ROOT xxxx True False\n",
      "you -PRON- PRON PRP ROOT xxx True True\n",
      "a a DET DT det x True True\n",
      "resting rest VERB VBG compound xxxx True False\n",
      "interval interval NOUN NN ROOT xxxx True False\n",
      "you -PRON- PRON PRP ROOT xxx True True\n",
      "you -PRON- PRON PRP ROOT xxx True True\n",
      "what what NOUN WP ROOT xxxx True True\n",
      "['variance ', 'good design ', 'resting interval ']\n",
      "\n",
      "For \"variance \":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Phenotype\n",
      "1: Allele\n",
      "2: Variance\n",
      "3: Genetic diversity\n",
      "4: Analysis of variance\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 2\n",
      "\n",
      "\n",
      "\n",
      "For \"good design \":\n",
      "0: Good Design Award\n",
      "1: Good Design Awards\n",
      "2: Do Good Design\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 2\n",
      "\n",
      "\n",
      "\n",
      "For \"resting interval \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Variance>', '<http://dbpedia.org/resource/Do_Good_Design>']\n",
      "\n",
      "21. Original Sentence:\n",
      "  Um this is what I do day in and day out\n",
      "what what NOUN WP ROOT xxxx True True\n",
      "I -PRON- PRON PRP ROOT X True False\n",
      "[]\n",
      "[]\n",
      "\n",
      "22. Original Sentence:\n",
      "  Um talk to designers and dream up solutions whether it's huge or um sports facilities or it's-\n",
      "designers designer NOUN NNS ROOT xxxx True False\n",
      "solutions solution NOUN NNS ROOT xxxx True False\n",
      "it -PRON- PRON PRP ROOT xx True True\n",
      "['designers ', 'solutions ']\n",
      "\n",
      "For \"designers \":\n",
      "0: Design\n",
      "1: Fashion design\n",
      "2: Graphic design\n",
      "3: Interior design\n",
      "4: Aerospace engineering\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"solutions \":\n",
      "0: Royal Dutch Shell\n",
      "1: Solution\n",
      "2: Philips\n",
      "3: Algebra\n",
      "4: Viacom\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Solution>']\n",
      "\n",
      "23. Original Sentence:\n",
      "a lotta fun to come to into the woods and change gears and do things differently\n",
      "the the DET DT det xxx True True\n",
      "woods wood NOUN NNS ROOT xxxx True False\n",
      "gears gear NOUN NNS ROOT xxxx True False\n",
      "things thing NOUN NNS ROOT xxxx True False\n",
      "['woods ', 'gears ', 'things ']\n",
      "\n",
      "For \"woods \":\n",
      "0: Forest\n",
      "1: Wood\n",
      "2: Woodland\n",
      "3: Beech\n",
      "4: Tiger Woods\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "\n",
      "For \"gears \":\n",
      "0: Undercarriage\n",
      "1: Mecha\n",
      "2: Gear\n",
      "3: Differential (mechanical device)\n",
      "4: Rack railway\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 2\n",
      "\n",
      "\n",
      "\n",
      "For \"things \":\n",
      "0: Organism\n",
      "1: Flag of the United States\n",
      "2: Sin\n",
      "3: Dharma\n",
      "4: Smallville\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Forest>', '<http://dbpedia.org/resource/Gear>']\n",
      "\n",
      "24. Original Sentence:\n",
      "  If it's site design and it goes through my office \n",
      "it -PRON- PRON PRP ROOT xx True True\n",
      "it -PRON- PRON PRP ROOT xx True True\n",
      "my -PRON- ADJ PRP$ poss xx True True\n",
      "office office NOUN NN ROOT xxxx True False\n",
      "['office ']\n",
      "\n",
      "For \"office \":\n",
      "0: Lawyer\n",
      "1: HBO\n",
      "2: United States Geological Survey\n",
      "3: Post office\n",
      "4: United States Postal Service\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "25. Original Sentence:\n",
      "\n",
      "[]\n",
      "[]\n",
      "\n",
      "26. Original Sentence:\n",
      "So we really envisioned the tree house to be a multipurpose but almost a loading area for the zip line\n",
      "we -PRON- PRON PRP ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "tree tree NOUN NN compound xxxx True False\n",
      "house house NOUN NN ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "zip zip NOUN NN compound xxx True False\n",
      "line line NOUN NN ROOT xxxx True False\n",
      "['tree house ', 'zip line ']\n",
      "\n",
      "For \"tree house \":\n",
      "0: Tree house\n",
      "1: List of monarchs of Mercia\n",
      "2: Treehouse of Horror\n",
      "3: Wuffingas\n",
      "4: Magic Tree House series\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "\n",
      "\n",
      "\n",
      "For \"zip line \":\n",
      "0: Zip-line\n",
      "1: Zip line\n",
      "2: Zipline Safari\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Tree_house>', '<http://dbpedia.org/resource/Zip_line>']\n",
      "\n",
      "27. Original Sentence:\n",
      " It's kind of where that decision was made with the plan zip line you have seen the zip line platform standing on that platform and hope to launch to your right across the valley is what our hope is that will then end up in the \n",
      "    SPACE     False False\n",
      "It -PRON- PRON PRP ROOT Xx True False\n",
      "that that DET DT det xxxx True True\n",
      "decision decision NOUN NN ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "plan plan NOUN NN amod xxxx True False\n",
      "zip zip NOUN NN compound xxx True False\n",
      "line line NOUN NN ROOT xxxx True False\n",
      "you -PRON- PRON PRP ROOT xxx True True\n",
      "the the DET DT det xxx True True\n",
      "zip zip NOUN NN compound xxx True False\n",
      "line line NOUN NN compound xxxx True False\n",
      "platform platform NOUN NN ROOT xxxx True False\n",
      "that that DET DT det xxxx True True\n",
      "platform platform NOUN NN ROOT xxxx True False\n",
      "your -PRON- ADJ PRP$ poss xxxx True True\n",
      "right right NOUN NN ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "valley valley NOUN NN ROOT xxxx True False\n",
      "our -PRON- ADJ PRP$ poss xxx True True\n",
      "hope hope NOUN NN ROOT xxxx True False\n",
      "['  ', 'decision ', 'plan zip line ', 'zip line platform ', 'platform ', 'right ', 'valley ', 'hope ']\n",
      "\n",
      "For \"  \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"decision \":\n",
      "0: United States presidential election, 2000\n",
      "1: Atomic bombings of Hiroshima and Nagasaki\n",
      "2: Surrender of Japan\n",
      "3: Regulation\n",
      "4: Certiorari\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"plan zip line \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"zip line platform \":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For \"platform \":\n",
      "0: Operating system\n",
      "1: Side platform\n",
      "2: Island platform\n",
      "3: Android (operating system)\n",
      "4: Yangtze River\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"right \":\n",
      "0: Midfielder\n",
      "1: Defender (association football)\n",
      "2: Batting (cricket)\n",
      "3: Human rights\n",
      "4: United States Constitution\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 3\n",
      "\n",
      "\n",
      "\n",
      "For \"valley \":\n",
      "0: Mississippi River\n",
      "1: Danube\n",
      "2: Rhine\n",
      "3: Las Vegas Valley\n",
      "4: Kosovo\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "\n",
      "For \"hope \":\n",
      "0: Cape of Good Hope\n",
      "1: Bob Hope\n",
      "2: Cape Colony\n",
      "3: Miley Cyrus\n",
      "4: University of Cape Town\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "\n",
      "['<http://dbpedia.org/resource/Human_rights>']\n",
      "\n",
      "28. Original Sentence:\n",
      "\n",
      "[]\n",
      "[]\n",
      "\n",
      "29. Original Sentence:\n",
      "\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if pred == \"be\":\\n    pred = \"type\"\\n#obj = \"person\"\\n\\n# look up the URI for subj, pred and obj\\nprint(\"\\nFor subject \"\" + subj + \"\":\")\\nsubjURI = QueryURI(subj)\\nprint(\"\\nFor predicate \"\" + pred + \"\":\")\\npredURI = QueryURI(pred)\\nprint(\"\\nFor object \"\" + obj + \"\":\")\\nobjURI = QueryURI(obj)\\n\\ntry:\\n    print(\"\\n\")\\n    print(\"subject: \" + subjURI[1:len(subjURI)-1])\\n    print(\"predicate: \" + predURI[1:len(predURI)-1])\\n    print(\"object: \" + objURI[1:len(objURI)-1])\\nexcept:\\n    print(\"none\")\\n    \\n# query the triple in dbpd with SPARQL\\n# queryResult = QueryTriple(subj, pred, obj)\\n# print(\\'Triple Query Result: \\' + str(queryResult))\\n\\n# query the triple with several different methods\\nr3 = ComponentQuery3(subjURI, predURI, objURI)\\nif r3:\\n    print(\"\\nFind origin component:\")\\n    print(subj + \\' - \\' + pred + \\' - \\' + obj)\\nelse:\\n    r2 = ComponentQuery2(subjURI, predURI, objURI)\\n    if r2 and len(r2)>0:\\n        print(\"\\nFind 2 components:\")\\n        PrintQueryResult(r2, subj, pred, obj)#print(r2) \\n    else:\\n        r1 = ComponentQuery1(subjURI, predURI, objURI)\\n        if r1 and len(r1)>0:\\n            print(\"\\nFind single component(s):\")\\n            if subjURI != None:\\n                print(subjURI[1:len(subjURI)-1])\\n            if predURI != None:\\n                print(predURI[1:len(predURI)-1])\\n            if objURI != None:\\n                print(objURI[1:len(objURI)-1])\\n            PrintQueryResult(r1, subj, pred, obj)#print(r1) \\n    \\n    #partial query\\n    result = PartialQuery(subj, pred, obj, subjURI, predURI, objURI)\\n    if not result:\\n        print (\"Find nothing in parial query\")'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "import json\n",
    "\n",
    "import urllib\n",
    "#from owlready2 import *\n",
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from allennlp.common.testing import AllenNlpTestCase\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# pre-processing\n",
    "def PreProcess(senSet):\n",
    "    #remove content between [ ]\n",
    "    print(\"Pre-processing...\")\n",
    "    for index in range(len(senSet)):\n",
    "        while senSet[index].find('[')>=0:\n",
    "            i_start = senSet[index].find('[')\n",
    "            i_end = senSet[index].find(']')\n",
    "            s = senSet[index][i_start:i_end+2]\n",
    "            senSet[index] = senSet[index].replace(s, \"\")\n",
    "            \n",
    "# stopwords from parsing the whole sentence\n",
    "def RemoveStopword1(phrase, doc, chunkStart, chunkEnd, stopList):\n",
    "    result = phrase\n",
    "    i_stop=0\n",
    "    #start = chunk.start# to eliminate the condition when the first word of chunk is stop word\n",
    "    for i_sen in range(chunkStart, chunkEnd):\n",
    "        while i_stop < len(stopList) and stopList[i_stop] < i_sen-1:\n",
    "            #print(str(stopList[i_stop]) + ' ' + str(i_sen))\n",
    "            i_stop = i_stop+1\n",
    "        # there is no stop word in current chunk\n",
    "        if i_stop >= len(stopList):\n",
    "            break;\n",
    "        #print(i_sen)\n",
    "        # finish going through the chunk\n",
    "        if stopList[i_stop] > chunkEnd-1:\n",
    "            break\n",
    "        # find the stop word and remove it\n",
    "        if stopList[i_stop] == i_sen-1:\n",
    "            #print(doc[i_sen-1])\n",
    "            if i_sen-1 == chunkStart:\n",
    "                result = result.replace(doc[i_sen-1].text + ' ', '')\n",
    "                chunkStart = chunkStart+1\n",
    "            else:\n",
    "                result = result.replace(' ' + doc[i_sen-1].text, '')\n",
    "    return result\n",
    "\n",
    "# stopwords from parsing triple separately\n",
    "def RemoveStopword2(inputPhrase):\n",
    "    result = ''\n",
    "    doc_phrase = nlp(str(inputPhrase))\n",
    "    for token in doc_phrase:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #       token.shape_, token.is_alpha, token.is_stop)\n",
    "        if not token.is_stop:\n",
    "            result = result + token.text + ' '\n",
    "        #else:\n",
    "        #    print(token.text + ', ', end = '')    \n",
    "    return result\n",
    "\n",
    "\n",
    "# extract one triple from given sentence\n",
    "def ExtractTriple(sen):\n",
    "    # initialize the triple and stop word list\n",
    "    subj = \"\"\n",
    "    pred = \"\"\n",
    "    obj = \"\"\n",
    "    stopList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "    \n",
    "    ## visualize the semantic tree\n",
    "    #options = {'compact': True, 'color': 'blue'}\n",
    "    #displacy.serve(doc, style='dep', options=options)\n",
    "    #displacy.serve(doc, style='dep')\n",
    "\n",
    "    print('\\nStopwords:')\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "        # record the index of stop words\n",
    "        if token.is_stop:\n",
    "            print(token.text + ', ', end='')\n",
    "            stopList.append(token.i)\n",
    "        if re.match('nsubj', token.dep_):   \n",
    "            subj = token.text\n",
    "        if re.match('ROOT', token.dep_): \n",
    "            pred = token.lemma_\n",
    "            pred_orig = token.text\n",
    "        if re.match('dobj', token.dep_): \n",
    "            obj = token.text\n",
    "            '''#an earlier solution that I find not necessary\n",
    "            obj = token.lemma_\n",
    "            # to avoid cases like \"-PRON-\"\n",
    "            if obj[0] == '-':\n",
    "                obj = token.text'''\n",
    "    print('\\n')\n",
    "\n",
    "    subj_1 = subj\n",
    "    obj_1 = obj\n",
    "    # using chunk to update subject and object\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.head.text == pred_orig and re.match('nsubj', chunk.root.dep_):\n",
    "            subj = chunk.text\n",
    "            # remove stop words\n",
    "            subj_1 = RemoveStopword1(subj, doc, chunk.start, chunk.end, stopList)\n",
    "\n",
    "        if chunk.root.head.text == pred_orig and re.match('dobj|attr', chunk.root.dep_):\n",
    "            obj = chunk.text\n",
    "            # remove stop words\n",
    "            obj_1 = RemoveStopword1(obj, doc, chunk.start, chunk.end, stopList)\n",
    "        #print(chunk.text + ' ' + str(chunk.start))\n",
    "        #print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
    "\n",
    "    #print('Before : ' + subj + ' - ' + pred + ' - ' + obj)\n",
    "    #print('Method1: ' + subj_1 + ' - ' + pred + ' - ' + obj_1)\n",
    "\n",
    "    # second method to remove stop words\n",
    "    subj_2 = RemoveStopword2(subj)\n",
    "    obj_2 = RemoveStopword2(obj)\n",
    "    #print('Method2: ' + subj_2 + '- ' + pred + ' - ' + obj_2 + '\\n')\n",
    "\n",
    "    return [subj, pred, obj]\n",
    "\n",
    "def QueryURI(keywords, index=-2):\n",
    "    localSite = 'http://localhost:1111/api/search/KeywordSearch?'\n",
    "    onlineSite = 'http://lookup.dbpedia.org/api/search/KeywordSearch?'\n",
    "    prefix = \"{http://lookup.dbpedia.org/}\"\n",
    "    \n",
    "    keywords = keywords.replace(' ', \"%20\")\n",
    "    request = onlineSite + \\\n",
    "    'QueryClass='   + ''  + \\\n",
    "    '&MaxHits='     + '5' + \\\n",
    "    '&QueryString=' + keywords\n",
    "    response = str(urllib.request.urlopen(request).read(), 'utf-8')\n",
    "\n",
    "    root = ET.fromstring(response)\n",
    "    result = root.findall(prefix + \"Result\")\n",
    "    \n",
    "    if len(result)>0:\n",
    "        selected = -1\n",
    "        count = 0\n",
    "        for name in result:\n",
    "            print(str(count) + \": \" + name.find(prefix + \"Label\").text)\n",
    "            count += 1\n",
    "        # for some default input during debugging\n",
    "        if index<-1:\n",
    "            index = int(input(\"Which one is closer to what you mean? (type \\\"-1\\\" if nothing seems correct) \"))\n",
    "        if index >= 0:\n",
    "            selected = \"<\" + result[index].find(prefix + \"URI\").text + \">\"\n",
    "        else:\n",
    "            selected = None\n",
    "        return selected\n",
    "    else:\n",
    "        print(\"Sorry, we find nothing for this stuff :(\\n\")\n",
    "        return None\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def FormatURI(phrase, isS_O = False):\n",
    "    #print('Before formatting:  ' + phrase)\n",
    "    chars = list(phrase)\n",
    "    \n",
    "    if len(chars) > 0 and not isS_O:\n",
    "        chars[0] = chars[0].upper()\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == ' ' and i+1 < len(chars):\n",
    "            chars[i+1] = chars[i+1].upper()\n",
    "    phrase = ''.join(chars)\n",
    "    phrase = phrase.replace(' ', '')\n",
    "    phrase = re.sub(r'[^a-zA-Z0-9\\s]', '', phrase)\n",
    "    #print('After formatting:  ' + phrase)\n",
    "    return phrase\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def NameURI(url):\n",
    "    index_slash = 0\n",
    "    for i in range(len(url)-1, -1, -1):\n",
    "        if url[i] == '/':\n",
    "            index_slash = i+1\n",
    "            break\n",
    "    return url[index_slash:]\n",
    "\n",
    "# query the given triple in the ontology with SPARQL\n",
    "# return true/false as result\n",
    "def QueryTriple(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"Province\"\n",
    "        qSelect = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "\n",
    "        r = list(m_graph.query(qAsk))\n",
    "        return r\n",
    "\n",
    "def ComponentQuery1(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    #subj = \"provinceLink\"\n",
    "    #pred = \"range\"\n",
    "    #obj = \"province\"\n",
    "    \n",
    "    r = []\n",
    "    if subj!=None:\n",
    "        qSelect_P_O = prefix + \"\"\"\n",
    "        SELECT ?pred ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred ?obj.\n",
    "        }\"\"\"\n",
    "        #r1 = m_graph.query(qSelect_P_O)\n",
    "        sparql.setQuery(qSelect_P_O)\n",
    "        r1 = sparql.query().convert()\n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if pred!=None:\n",
    "        qSelect_S_O = prefix + \"\"\"\n",
    "        SELECT ?sub ?obj WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        #r2 = m_graph.query(qSelect_S_O) \n",
    "        sparql.setQuery(qSelect_S_O)\n",
    "        r2 = sparql.query().convert()\n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "        \n",
    "    if obj!=None:\n",
    "        qSelect_S_P = prefix + \"\"\"\n",
    "        SELECT ?sub ?pred WHERE {\n",
    "          ?sub ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        #r3 = m_graph.query(qSelect_S_P) \n",
    "        sparql.setQuery(qSelect_S_P)\n",
    "        r3 = sparql.query().convert()\n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "\n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery2(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"    \n",
    "    \n",
    "    r = []\n",
    "    if pred!=None and obj!=None:\n",
    "        qSelect_S = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r1 = m_graph.query(qSelect_S) \n",
    "        sparql.setQuery(qSelect_S)\n",
    "        r1 = sparql.query().convert()\n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if subj!=None and obj!=None:\n",
    "        qSelect_P = prefix + \"\"\"\n",
    "        SELECT ?pred WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r2 = m_graph.query(qSelect_P)\n",
    "        sparql.setQuery(qSelect_P)\n",
    "        r2 = sparql.query().convert()\n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "            \n",
    "    if subj!=None and pred!=None:\n",
    "        qSelect_O = prefix + \"\"\"\n",
    "        SELECT ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        \n",
    "        #r3 = m_graph.query(qSelect_O)\n",
    "        sparql.setQuery(qSelect_O)\n",
    "        r3 = sparql.query().convert()\n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "        \n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    #PrintQueryResult(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery3(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"province\"\n",
    "\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK WHERE {\n",
    "            \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\"\n",
    "        }\"\"\"\n",
    "        #print(qAsk)\n",
    "\n",
    "        #r = m_graph.query(qAsk)\n",
    "        sparql.setQuery(qAsk)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        r = sparql.query().convert()\n",
    "\n",
    "        #if not r:\n",
    "        #    print(qAsk)\n",
    "        #    print(r)\n",
    "        \n",
    "        return r[\"boolean\"]\n",
    "\n",
    "def PartialQuery(subj, pred, obj, subjURI, predURI, objURI):\n",
    "    if subj==None and pred==None and obj==None:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n*********************** In Partial Query *************************\")\n",
    "    doc_subj = nlp(str(subj))\n",
    "    doc_pred = nlp(str(pred))\n",
    "    doc_obj = nlp(str(obj))\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    r3 = False\n",
    "    \n",
    "    for token_subj in doc_subj:\n",
    "        # get the URI for partial subj\n",
    "        if len(doc_subj)>1:\n",
    "            print(\"\\nFor partial subject \\\"\" + token_subj.text + \"\\\":\")\n",
    "            part_subj = QueryURI(token_subj.text)\n",
    "        else:\n",
    "            part_subj = subjURI\n",
    "            \n",
    "        for token_pred in doc_pred:\n",
    "            # get the URI for partial pred\n",
    "            if len(doc_pred)>1:\n",
    "                print(\"\\nFor partial predicate \\\"\" + token_pred.text + \"\\\":\")\n",
    "                part_pred = QueryURI(token_pred.text)\n",
    "            else:\n",
    "                part_pred = predURI\n",
    "                \n",
    "            for token_obj in doc_obj:\n",
    "                #print(token_obj.text, token_obj.lemma_, token_obj.pos_, token_obj.tag_, token_obj.dep_,\n",
    "                #      token_obj.shape_, token_obj.is_alpha, token_obj.is_stop)\n",
    "                if token_subj.is_stop and token_pred.is_stop and token_obj.is_stop:\n",
    "                    continue\n",
    "                    \n",
    "                # get the URI for partial obj\n",
    "                if len(doc_obj)>1:\n",
    "                    print(\"\\nFor partial object \\\"\" + token_obj.text + \"\\\":\")\n",
    "                    part_obj = QueryURI(token_obj.text)\n",
    "                else:\n",
    "                    part_obj = objURI\n",
    "\n",
    "                r1 = ComponentQuery1(part_subj, part_pred, part_obj)\n",
    "                #print(r1)\n",
    "                if r1 and len(r1)>0:\n",
    "                    r2 = ComponentQuery2(part_subj, part_pred, part_obj)\n",
    "                    r2Result = False\n",
    "                    for group in r2:\n",
    "                        for result in group[\"results\"][\"bindings\"]:\n",
    "                            if len(result) > 0:\n",
    "                                r2Result = True\n",
    "                    if r2Result:\n",
    "                        r3 = ComponentQuery3(part_subj, part_pred, part_obj)\n",
    "                        if r3:\n",
    "                            print(\"\\nFind triple with 3 partial components:\")\n",
    "                            print(part_subj + \" - \" + part_pred + \" - \" + part_obj)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"\\nFind triple with 2 partial components\")\n",
    "                            PrintQueryResult(r2, part_subj, part_pred, part_obj)\n",
    "                            #print(r2)\n",
    "                    else:\n",
    "                        print(\"\\nFind single partial component(s):\")\n",
    "                        if part_subj != None:\n",
    "                            print(part_subj[1:len(part_subj)-1])\n",
    "                        if part_pred != None:\n",
    "                            print(part_pred[1:len(part_pred)-1])\n",
    "                        if part_obj != None:\n",
    "                            print(part_obj[1:len(part_obj)-1])\n",
    "                        PrintQueryResult(r1, part_subj, part_pred, part_obj)\n",
    "    \n",
    "    return True\n",
    "    #return len(r1)>0 or r2Result or r3\n",
    "\n",
    "# given a URI, query the ontology iteratively to get its path to root\n",
    "def QueryHierarchy(URI):\n",
    "    path = []\n",
    "    path.insert(0, URI)\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    curURI = URI\n",
    "    predicate = \"rdf:type\"\n",
    "    endFlag = False # to mark whether a dbo:entity is found in current level\n",
    "    \n",
    "    while not endFlag:\n",
    "        endFlag = True;\n",
    "        \n",
    "        qSelect = \"\"\"\n",
    "            SELECT ?type WHERE \n",
    "            {\n",
    "            \"\"\" + curURI + predicate + \"\"\" ?type.\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(qSelect)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            resultURI = '<' + result[\"type\"][\"value\"] + '>'\n",
    "            # begin the class part\n",
    "            if \"owl#Class\" in resultURI:\n",
    "                endFlag = False;\n",
    "                predicate = \"rdfs:subClassOf\"\n",
    "                break;\n",
    "            # insert the first found dbo:entity into the path\n",
    "            elif \"http://dbpedia.org/ontology\" in resultURI:\n",
    "                endFlag = False;\n",
    "                curURI = resultURI\n",
    "                path.insert(0, resultURI)\n",
    "                break;\n",
    "     \n",
    "    # insert the common root node to current path\n",
    "    path.insert(0, '<http://www.w3.org/2002/07/owl#Thing>')\n",
    "    return path\n",
    "            \n",
    "# get ontology hierarchy for every keyword and append the knowledge tree\n",
    "def AppendTree(URIList, treeDict):\n",
    "    for URI in URIList:\n",
    "        hierarchy = QueryHierarchy(URI);\n",
    "        #print(hierarchy)\n",
    "        \n",
    "        curDict = treeDict;\n",
    "        for curKey in hierarchy:\n",
    "            if curKey in curDict:\n",
    "                curDict = curDict[curKey]\n",
    "            else:\n",
    "                curDict[curKey] = dict()\n",
    "                curDict = curDict[curKey]\n",
    "    \n",
    "# A recursive helper function to traverse treeDict and format it to json\n",
    "def PreorderFormat(curDict):\n",
    "    if len(curDict) == 0:\n",
    "        return;\n",
    "    \n",
    "    childList = []\n",
    "    for key in curDict:\n",
    "        children = PreorderFormat(curDict[key])\n",
    "        if children:\n",
    "            childList.append({\n",
    "                \"name\": key,\n",
    "                \"children\": children\n",
    "            })\n",
    "        else:\n",
    "            childList.append({\n",
    "                \"name\": key\n",
    "            })\n",
    "    return childList\n",
    "    \n",
    "        \n",
    "def FormatToJson(treeDict):\n",
    "    result = PreorderFormat(treeDict)\n",
    "    finalResult = None\n",
    "    if result:\n",
    "        finalResult = {\n",
    "            \"name\": \"GroundRoot\",\n",
    "            \"children\": result\n",
    "        }\n",
    "    return finalResult\n",
    "\n",
    "def PrintQueryResult(results, sub, pred, obj):\n",
    "    # for sparqlWrapper\n",
    "    for group in results:\n",
    "        #print(group)\n",
    "        for result in group[\"results\"][\"bindings\"]:\n",
    "            print('( ', end='')\n",
    "            if \"sub\" in result:\n",
    "                print(NameURI(result[\"sub\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in sub:\n",
    "                    sub = sub[29:-1]\n",
    "                print(sub + ' -', end='')\n",
    "            if \"pred\" in result:\n",
    "                print(NameURI(result[\"pred\"][\"value\"]) + ' - ', end='')\n",
    "            else:\n",
    "                if '<' in pred:\n",
    "                    pred = pred[29:-1]\n",
    "                print(pred + ' -', end='')\n",
    "            if \"obj\" in result:\n",
    "                print(NameURI(result[\"obj\"][\"value\"]) + ' )\\n', end='')\n",
    "            else:\n",
    "                if '<' in obj:\n",
    "                    obj = obj[29:-1]\n",
    "                print(obj + ' )\\n', end='')\n",
    "        \n",
    "    '''# for owlready\n",
    "    for result in results:\n",
    "        for var in result.vars:\n",
    "            print(var.toPython())\n",
    "        for binding in result.bindings:\n",
    "            print(binding.toPython())'''\n",
    "    \n",
    "# extract one triple from given sentence\n",
    "def RunNER(sen):\n",
    "    # initialize the named entity list\n",
    "    entityList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "\n",
    "    #ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if \"subj\" in chunk.root.dep_ or \"obj\" in chunk.root.dep_:\n",
    "            # test whether current chunk is or contains stop words\n",
    "            result = ''\n",
    "            doc_phrase = nlp(chunk.text)\n",
    "            for token in doc_phrase:\n",
    "                #print(token.text, token.is_stop, token.lemma_)\n",
    "                if not token.is_stop and token.lemma_ != \"-PRON-\":\n",
    "                # exclude stop words and personal pronouns (whose lemma_ is \"-PRON-\")\n",
    "                    result = result + token.text + ' '\n",
    "            \n",
    "            if result != '':\n",
    "                chunks.append(result)\n",
    "    \n",
    "    return chunks\n",
    "        \n",
    "# load Spacy NLP dictionary\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load DBPD ontology and construct graph for query\n",
    "#m_world = World()# Owlready2 stores every triples in a â€˜Worldâ€™ object\n",
    "#m_onto = m_world.get_ontology(\"dbpedia.owl\").load()\n",
    "#m_graph = m_world.as_rdflib_graph()\n",
    "#sparql = SPARQLWrapper(\"dbpedia.owl\")#http://dbpedia.org/sparql\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "# load data\n",
    "file = open(\"shortdataset.csv\", \"r\")\n",
    "#file = open(\"newdataset_formatted.csv\", \"r\")\n",
    "reader = csv.reader(file)\n",
    "senSet = []\n",
    "for item in reader:\n",
    "    #format sentences in item as string\n",
    "    fullP = \"\".join(item)\n",
    "    splitP = fullP.split(\";\", 3);\n",
    "    splitS = splitP[3][1:len(splitP[3])].split(\".\");\n",
    "    #print(splitS)\n",
    "    for sen in splitS:\n",
    "        senSet.append(sen)#store the sentence into an array\n",
    "file.close()\n",
    "print(\"Total sentences: \" + str(len(senSet)))\n",
    "\n",
    "# pre-processing\n",
    "PreProcess(senSet)\n",
    "\n",
    "treeDict = dict()\n",
    "# parse and query each sentence\n",
    "for index in range(10, 30):\n",
    "#for index in range(len(senSet)):\n",
    "    #index = 26\n",
    "    #sampleSentence = \"Do you remember the administrator of this computer?\"\n",
    "    sampleSentence = \"Neverland has the tree house.\"\n",
    "\n",
    "    # extract named entities from current sentence\n",
    "    #entityList = RunNER(sampleSentence)\n",
    "    entityList = RunNER(senSet[index])\n",
    "    print(entityList)\n",
    "\n",
    "    # look up the URI for the entities\n",
    "    URIList = []\n",
    "    for entity in entityList:\n",
    "        print(\"\\nFor \\\"\" + entity + \"\\\":\")\n",
    "        entityURI = QueryURI(entity)\n",
    "\n",
    "        try:\n",
    "            print(\"\\n\")\n",
    "            #print(\"URI: \" + entityURI[1:len(entityURI)-1])\n",
    "            if entityURI != None:\n",
    "                URIList.append(entityURI)\n",
    "        except:\n",
    "            print(\"none\")\n",
    "\n",
    "    print(URIList)\n",
    "\n",
    "    if len(URIList)>0:\n",
    "        AppendTree(URIList, treeDict)\n",
    "\n",
    "treeJson = FormatToJson(treeDict)\n",
    "#print(treeJson)\n",
    "\n",
    "with open('../IdeaTest/Tree/conv-test.json', 'w') as outfile:  \n",
    "    json.dump(treeJson, outfile, indent = 2)\n",
    "\n",
    "#for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "#    print(f\"{word}\\t{tag}\")\n",
    "\n",
    "#subj = \"province link\"\n",
    "'''if pred == \"be\":\n",
    "    pred = \"type\"\n",
    "#obj = \"person\"\n",
    "\n",
    "# look up the URI for subj, pred and obj\n",
    "print(\"\\nFor subject \\\"\" + subj + \"\\\":\")\n",
    "subjURI = QueryURI(subj)\n",
    "print(\"\\nFor predicate \\\"\" + pred + \"\\\":\")\n",
    "predURI = QueryURI(pred)\n",
    "print(\"\\nFor object \\\"\" + obj + \"\\\":\")\n",
    "objURI = QueryURI(obj)\n",
    "\n",
    "try:\n",
    "    print(\"\\n\")\n",
    "    print(\"subject: \" + subjURI[1:len(subjURI)-1])\n",
    "    print(\"predicate: \" + predURI[1:len(predURI)-1])\n",
    "    print(\"object: \" + objURI[1:len(objURI)-1])\n",
    "except:\n",
    "    print(\"none\")\n",
    "    \n",
    "# query the triple in dbpd with SPARQL\n",
    "# queryResult = QueryTriple(subj, pred, obj)\n",
    "# print('Triple Query Result: ' + str(queryResult))\n",
    "\n",
    "# query the triple with several different methods\n",
    "r3 = ComponentQuery3(subjURI, predURI, objURI)\n",
    "if r3:\n",
    "    print(\"\\nFind origin component:\")\n",
    "    print(subj + ' - ' + pred + ' - ' + obj)\n",
    "else:\n",
    "    r2 = ComponentQuery2(subjURI, predURI, objURI)\n",
    "    if r2 and len(r2)>0:\n",
    "        print(\"\\nFind 2 components:\")\n",
    "        PrintQueryResult(r2, subj, pred, obj)#print(r2) \n",
    "    else:\n",
    "        r1 = ComponentQuery1(subjURI, predURI, objURI)\n",
    "        if r1 and len(r1)>0:\n",
    "            print(\"\\nFind single component(s):\")\n",
    "            if subjURI != None:\n",
    "                print(subjURI[1:len(subjURI)-1])\n",
    "            if predURI != None:\n",
    "                print(predURI[1:len(predURI)-1])\n",
    "            if objURI != None:\n",
    "                print(objURI[1:len(objURI)-1])\n",
    "            PrintQueryResult(r1, subj, pred, obj)#print(r1) \n",
    "    \n",
    "    #partial query\n",
    "    result = PartialQuery(subj, pred, obj, subjURI, predURI, objURI)\n",
    "    if not result:\n",
    "        print (\"Find nothing in parial query\")'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to remove WARNINGs from Owlready2\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31050\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "DESCRIBE not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b27ce1a90687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m DESCRIBE ?sub WHERE {\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m?\u001b[0m\u001b[0msub\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m  \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvince\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m }\"\"\"))\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         return result(processor.query(\n\u001b[0;32m-> 1089\u001b[0;31m             query_object, initBindings, initNs, **kwargs))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     def update(self, update_object, processor='sparql',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/processor.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrOrQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevalQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitBindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalQuery\u001b[0;34m(graph, query, initBindings, base)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevalPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalPart\u001b[0;34m(ctx, part)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DescribeQuery'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DESCRIBE not implemented'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: DESCRIBE not implemented"
     ]
    }
   ],
   "source": [
    "# reference: https://pythonhosted.org/Owlready2/world.html\n",
    "from owlready2 import *\n",
    "import rdflib\n",
    "\n",
    "my_world = World()# Owlready2 stores every triples in a â€˜Worldâ€™ object\n",
    "onto = my_world.get_ontology(\"dbpedia.owl\").load()\n",
    "\n",
    "graph = my_world.as_rdflib_graph()\n",
    "print(len(graph))\n",
    "\n",
    "prefix = \"\"\"\n",
    "PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "SELECT ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "ASK {\n",
    "  dbpd:provinceLink rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "r = list(graph.query(prefix + \"\"\"\n",
    "DESCRIBE ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Root Level', 'children': [{'name': 'Top Level', 'children': [{'name': 'TestTTTTT', 'children': [{'name': 'Child1 of A'}, {'name': 'Child2 of A', 'children': [{'name': 'Child1 of Child2'}, {'name': 'Child2 of Child2'}, {'name': 'Child3 of Child2'}]}, {'name': 'Child3 of A'}, {'name': 'Child4 of A'}, {'name': 'Child5 of A'}]}, {'name': 'Level 2: B', 'children': [{'name': 'Child1 of B'}, {'name': 'Child2 of B'}, {'name': 'Child3 of B'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    \"name\": \"Root Level\",\n",
    "    \"children\": [{ \n",
    "        \"name\": \"Top Level\",\n",
    "        \"children\": [{ \n",
    "            \"name\": \"Level 2: A\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of A\" },\n",
    "                    { \"name\": \"Child2 of A\",\n",
    "                        \"children\": [\n",
    "                            { \"name\": \"Child1 of Child2\" },\n",
    "                            { \"name\": \"Child2 of Child2\" },\n",
    "                            { \"name\": \"Child3 of Child2\" }\n",
    "                        ]\n",
    "                    },\n",
    "                    { \"name\": \"Child3 of A\" },\n",
    "                    { \"name\": \"Child4 of A\" },\n",
    "                    { \"name\": \"Child5 of A\" }\n",
    "                ]\n",
    "            },\n",
    "            { \n",
    "                \"name\": \"Level 2: B\",\n",
    "                \"children\": [\n",
    "                    { \"name\": \"Child1 of B\" },\n",
    "                    { \"name\": \"Child2 of B\" },\n",
    "                    { \"name\": \"Child3 of B\" }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "}\n",
    "\n",
    "# print(d)\n",
    "\n",
    "node = d[\"children\"][0][\"children\"][0]\n",
    "node[\"name\"] = \"TestTTTTT\"\n",
    "\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
