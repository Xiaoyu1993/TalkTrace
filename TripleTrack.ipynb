{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './server_resource/dbpedia.owl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-192ec842785b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Year_1/Ontology/TalkTrace/server.py\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# load DBPD ontology and construct graph for query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mm_world\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Owlready2 stores every triples in a ‘World’ object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mm_onto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ontology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./server_resource/dbpedia.owl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0mm_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_rdflib_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/owlready2/namespace.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, only_local, fileobj, reload, reload_if_newer, **args)\u001b[0m\n\u001b[1;32m    621\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreload\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreload_if_newer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_update_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_update_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_LOG_LEVEL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"* Owlready2 *     ...loading ontology %s from %s...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mnew_base_iri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_iri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './server_resource/dbpedia.owl'"
     ]
    }
   ],
   "source": [
    "import server\n",
    "server.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 46\n",
      "Pre-processing...\n",
      "\n",
      "2. Original Sentence:\n",
      "  Um we manage all the construction and innovation projects for the university across the state\n",
      "\n",
      "Stopwords:\n",
      "we, all, the, and, for, the, across, the, \n",
      "\n",
      "Triple to Query: \n",
      "we - manage - all the construction and innovation projects\n",
      "\n",
      "For subject \"we\":\n",
      "0: Daily Mirror\n",
      "1: William Ewart Gladstone\n",
      "2: Ron Paul\n",
      "3: Warsaw Uprising\n",
      "4: Linkin Park\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "\n",
      "For predicate \"manage\":\n",
      "0: Head coach\n",
      "1: Management\n",
      "2: Manager (baseball)\n",
      "3: Manager (association football)\n",
      "4: Manager (professional wrestling)\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 1\n",
      "\n",
      "For object \"all the construction and innovation projects\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "\n",
      "\n",
      "none\n",
      "\n",
      "*********************** In Partial Query *************************\n",
      "\n",
      "For partial object \"all\":\n",
      "0: Allmusic\n",
      "1: All-America\n",
      "2: Aluminium\n",
      "3: Big Ten Conference\n",
      "4: Southeastern Conference\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "?sub\n",
      "?obj\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f2929b3acc0>]\n",
      "\n",
      "Find triple with 1 components:\n",
      "?sub\n",
      "?obj\n",
      "\n",
      "For partial object \"the\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "?sub\n",
      "?obj\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f29439c58d0>]\n",
      "\n",
      "Find triple with 1 components:\n",
      "?sub\n",
      "?obj\n",
      "\n",
      "For partial object \"construction\":\n",
      "0: Construction\n",
      "1: Civil engineering\n",
      "2: Grammar\n",
      "3: Road\n",
      "4: Timber framing\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 0\n",
      "?sub\n",
      "?obj\n",
      "?sub\n",
      "?pred\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f294200af98>, <rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f292e780d68>]\n",
      "\n",
      "Find triple with 2 components:\n",
      "?sub\n",
      "\n",
      "For partial object \"and\":\n",
      "Sorry, we find nothing for this stuff :(\n",
      "\n",
      "?sub\n",
      "?obj\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f292eaacd68>]\n",
      "\n",
      "Find triple with 1 components:\n",
      "?sub\n",
      "?obj\n",
      "\n",
      "For partial object \"innovation\":\n",
      "0: Charter school\n",
      "1: Ministry (government department)\n",
      "2: Innovation\n",
      "3: Military tactics\n",
      "4: Creativity\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) 2\n",
      "?sub\n",
      "?obj\n",
      "?sub\n",
      "?pred\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f292eaacb00>, <rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f2929f37278>]\n",
      "\n",
      "Find triple with 2 components:\n",
      "?sub\n",
      "\n",
      "For partial object \"projects\":\n",
      "0: Construction\n",
      "1: Works Progress Administration\n",
      "2: Infrastructure\n",
      "3: Real estate development\n",
      "4: Mission (Christianity)\n",
      "Which one is closer to what you mean? (type \"-1\" if nothing seems correct) -1\n",
      "?sub\n",
      "?obj\n",
      "[<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7f2929b3aac8>]\n",
      "\n",
      "Find triple with 1 components:\n",
      "?sub\n",
      "?obj\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import urllib\n",
    "from owlready2 import *\n",
    "from rdflib import Graph\n",
    "\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from allennlp.common.testing import AllenNlpTestCase\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# pre-processing\n",
    "def PreProcess(senSet):\n",
    "    #remove content between [ ]\n",
    "    print(\"Pre-processing...\")\n",
    "    for index in range(len(senSet)):\n",
    "        while senSet[index].find('[')>=0:\n",
    "            i_start = senSet[index].find('[')\n",
    "            i_end = senSet[index].find(']')\n",
    "            s = senSet[index][i_start:i_end+2]\n",
    "            senSet[index] = senSet[index].replace(s, \"\")\n",
    "            \n",
    "# stopwords from parsing the whole sentence\n",
    "def RemoveStopword1(phrase, doc, chunkStart, chunkEnd, stopList):\n",
    "    result = phrase\n",
    "    i_stop=0\n",
    "    #start = chunk.start# to eliminate the condition when the first word of chunk is stop word\n",
    "    for i_sen in range(chunkStart, chunkEnd):\n",
    "        while i_stop < len(stopList) and stopList[i_stop] < i_sen-1:\n",
    "            #print(str(stopList[i_stop]) + ' ' + str(i_sen))\n",
    "            i_stop = i_stop+1\n",
    "        # there is no stop word in current chunk\n",
    "        if i_stop >= len(stopList):\n",
    "            break;\n",
    "        #print(i_sen)\n",
    "        # finish going through the chunk\n",
    "        if stopList[i_stop] > chunkEnd-1:\n",
    "            break\n",
    "        # find the stop word and remove it\n",
    "        if stopList[i_stop] == i_sen-1:\n",
    "            #print(doc[i_sen-1])\n",
    "            if i_sen-1 == chunkStart:\n",
    "                result = result.replace(doc[i_sen-1].text + ' ', '')\n",
    "                chunkStart = chunkStart+1\n",
    "            else:\n",
    "                result = result.replace(' ' + doc[i_sen-1].text, '')\n",
    "    return result\n",
    "\n",
    "# stopwords from parsing triple separately\n",
    "def RemoveStopword2(inputPhrase):\n",
    "    result = ''\n",
    "    doc_phrase = nlp(str(inputPhrase))\n",
    "    for token in doc_phrase:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #       token.shape_, token.is_alpha, token.is_stop)\n",
    "        if not token.is_stop:\n",
    "            result = result + token.text + ' '\n",
    "        #else:\n",
    "        #    print(token.text + ', ', end = '')    \n",
    "    return result\n",
    "\n",
    "\n",
    "# extract one triple from given sentence\n",
    "def ExtractTriple(sen):\n",
    "    # initialize the triple and stop word list\n",
    "    subj = \"\"\n",
    "    pred = \"\"\n",
    "    obj = \"\"\n",
    "    stopList = []\n",
    "    \n",
    "    # parse sentence\n",
    "    doc = nlp(str(sen))\n",
    "    print('\\n' + str(index) + '. Original Sentence:\\n' + sen)\n",
    "    \n",
    "    ## visualize the semantic tree\n",
    "    #options = {'compact': True, 'color': 'blue'}\n",
    "    #displacy.serve(doc, style='dep', options=options)\n",
    "    #displacy.serve(doc, style='dep')\n",
    "\n",
    "    print('\\nStopwords:')\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "        # record the index of stop words\n",
    "        if token.is_stop:\n",
    "            print(token.text + ', ', end='')\n",
    "            stopList.append(token.i)\n",
    "        if re.match('nsubj', token.dep_):   \n",
    "            subj = token.text\n",
    "        if re.match('ROOT', token.dep_): \n",
    "            pred = token.lemma_\n",
    "            pred_orig = token.text\n",
    "        if re.match('dobj', token.dep_): \n",
    "            obj = token.text\n",
    "            '''#an earlier solution that I find not necessary\n",
    "            obj = token.lemma_\n",
    "            # to avoid cases like \"-PRON-\"\n",
    "            if obj[0] == '-':\n",
    "                obj = token.text'''\n",
    "    print('\\n')\n",
    "\n",
    "    subj_1 = subj\n",
    "    obj_1 = obj\n",
    "    # using chunk to update subject and object\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.head.text == pred_orig and re.match('nsubj', chunk.root.dep_):\n",
    "            subj = chunk.text\n",
    "            # remove stop words\n",
    "            subj_1 = RemoveStopword1(subj, doc, chunk.start, chunk.end, stopList)\n",
    "\n",
    "        if chunk.root.head.text == pred_orig and re.match('dobj|attr', chunk.root.dep_):\n",
    "            obj = chunk.text\n",
    "            # remove stop words\n",
    "            obj_1 = RemoveStopword1(obj, doc, chunk.start, chunk.end, stopList)\n",
    "        #print(chunk.text + ' ' + str(chunk.start))\n",
    "        #print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
    "\n",
    "    #print('Before : ' + subj + ' - ' + pred + ' - ' + obj)\n",
    "    #print('Method1: ' + subj_1 + ' - ' + pred + ' - ' + obj_1)\n",
    "\n",
    "    # second method to remove stop words\n",
    "    subj_2 = RemoveStopword2(subj)\n",
    "    obj_2 = RemoveStopword2(obj)\n",
    "    #print('Method2: ' + subj_2 + '- ' + pred + ' - ' + obj_2 + '\\n')\n",
    "\n",
    "    return [subj, pred, obj]\n",
    "\n",
    "def QueryURI(keywords, index=-2):\n",
    "    localSite = 'http://localhost:1111/api/search/KeywordSearch?'\n",
    "    onlineSite = 'http://lookup.dbpedia.org/api/search/KeywordSearch?'\n",
    "    prefix = \"{http://lookup.dbpedia.org/}\"\n",
    "    \n",
    "    keywords = keywords.replace(' ', \"%20\")\n",
    "    request = onlineSite + \\\n",
    "    'QueryClass='   + ''  + \\\n",
    "    '&MaxHits='     + '5' + \\\n",
    "    '&QueryString=' + keywords\n",
    "    response = str(urllib.request.urlopen(request).read(), 'utf-8')\n",
    "\n",
    "    root = ET.fromstring(response)\n",
    "    result = root.findall(prefix + \"Result\")\n",
    "    \n",
    "    if len(result)>0:\n",
    "        selected = -1\n",
    "        count = 0\n",
    "        for name in result:\n",
    "            print(str(count) + \": \" + name.find(prefix + \"Label\").text)\n",
    "            count += 1\n",
    "        # for some default input during debugging\n",
    "        if index<-1:\n",
    "            index = int(input(\"Which one is closer to what you mean? (type \\\"-1\\\" if nothing seems correct) \"))\n",
    "        if index >= 0:\n",
    "            selected = \"<\" + result[index].find(prefix + \"URI\").text + \">\"\n",
    "        else:\n",
    "            selected = None\n",
    "        return selected\n",
    "    else:\n",
    "        print(\"Sorry, we find nothing for this stuff :(\\n\")\n",
    "        return None\n",
    "\n",
    "# transfer a phrase to a URI form\n",
    "def FormatURI(phrase, isS_O = False):\n",
    "    #print('Before formatting:  ' + phrase)\n",
    "    chars = list(phrase)\n",
    "    \n",
    "    if len(chars) > 0 and not isS_O:\n",
    "        chars[0] = chars[0].upper()\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == ' ' and i+1 < len(chars):\n",
    "            chars[i+1] = chars[i+1].upper()\n",
    "    phrase = ''.join(chars)\n",
    "    phrase = phrase.replace(' ', '')\n",
    "    phrase = re.sub(r'[^a-zA-Z0-9\\s]', '', phrase)\n",
    "    #print('After formatting:  ' + phrase)\n",
    "    return phrase\n",
    "\n",
    "# query the given triple in the ontology with SPARQL\n",
    "# return true/false as result\n",
    "def QueryTriple(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"Province\"\n",
    "        qSelect = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            dbpd:\"\"\" + FormatURI(subj) + \"\"\" rdf:\"\"\" + FormatURI(pred) + \"\"\" dbpd:\"\"\" + FormatURI(obj) + \"\"\".\n",
    "        }\"\"\"\n",
    "\n",
    "        r = list(m_graph.query(qAsk))\n",
    "        return r\n",
    "\n",
    "def ComponentQuery1(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    #subj = \"provinceLink\"\n",
    "    #pred = \"range\"\n",
    "    #obj = \"province\"\n",
    "    \n",
    "    r = []\n",
    "    if subj!=None:\n",
    "        qSelect_P_O = prefix + \"\"\"\n",
    "        SELECT ?pred ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred ?obj.\n",
    "        }\"\"\"\n",
    "        # print(qSelect_P_O)\n",
    "        r1 = m_graph.query(qSelect_P_O) \n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if pred!=None:\n",
    "        qSelect_S_O = prefix + \"\"\"\n",
    "        SELECT ?sub ?obj WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        # print(qSelect_S_O)\n",
    "        r2 = m_graph.query(qSelect_S_O) \n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "        \n",
    "    if obj!=None:\n",
    "        qSelect_S_P = prefix + \"\"\"\n",
    "        SELECT ?sub ?pred WHERE {\n",
    "          ?sub ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        # print(qSelect_S_P)\n",
    "        r3 = m_graph.query(qSelect_S_P) \n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "\n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    PrintQueryResult(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery2(subj, pred, obj):\n",
    "    prefix = \"\"\"\n",
    "    PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "    \"\"\"\n",
    "    \n",
    "    r = []\n",
    "    if pred!=None and obj!=None:\n",
    "        qSelect_S = prefix + \"\"\"\n",
    "        SELECT ?sub WHERE {\n",
    "          ?sub \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        #print(qSelect_S)\n",
    "        #print(\"\\nFind triple with 2 components: \\n\" + pred + ' - ' + obj)\n",
    "        r1 = m_graph.query(qSelect_S) \n",
    "        if r1 != None: # may need one more variable to record source\n",
    "            r.append(r1)\n",
    "        \n",
    "    if subj!=None and obj!=None:\n",
    "        qSelect_P = prefix + \"\"\"\n",
    "        SELECT ?pred WHERE {\n",
    "          \"\"\" + subj + \"\"\" ?pred \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "        #print(qSelect_P)\n",
    "        #print(\"\\nFind triple with 2 components: \\n\" + subj + ' - ' + obj)\n",
    "        r2 = m_graph.query(qSelect_P)\n",
    "        if r2 != None: # may need one more variable to record source\n",
    "            r.append(r2)\n",
    "            \n",
    "    if subj!=None and pred!=None:\n",
    "        qSelect_O = prefix + \"\"\"\n",
    "        SELECT ?obj WHERE {\n",
    "          \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" ?obj.\n",
    "        }\"\"\"\n",
    "        #print(qSelect_O)\n",
    "        #print(\"\\nFind triple with 2 components: \\n\" + subj + ' - ' + pred)\n",
    "        r3 = m_graph.query(qSelect_O)\n",
    "        if r3 != None: # may need one more variable to record source\n",
    "            r.append(r3)\n",
    "        \n",
    "    #if r!=[]:\n",
    "    #    print(r)\n",
    "    #PrintQueryResult(r)\n",
    "    return r\n",
    "\n",
    "def ComponentQuery3(subj, pred, obj):\n",
    "    if subj==None or pred==None or obj==None:\n",
    "        return None\n",
    "    else:\n",
    "        prefix = \"\"\"\n",
    "        PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "        \"\"\"\n",
    "        #subj = \"provinceLink\"\n",
    "        #pred = \"range\"\n",
    "        #obj = \"province\"\n",
    "\n",
    "        qAsk = prefix + \"\"\"\n",
    "        ASK {\n",
    "            \"\"\" + subj + \"\"\" \"\"\" + pred + \"\"\" \"\"\" + obj + \"\"\".\n",
    "        }\"\"\"\n",
    "\n",
    "        r = m_graph.query(qAsk)\n",
    "\n",
    "        #if not r:\n",
    "        #    print(qAsk)\n",
    "        #    print(r)\n",
    "        return r.askAnswer\n",
    "\n",
    "def PartialQuery(subj, pred, obj, subjURI, predURI, objURI):\n",
    "    if subj==None and pred==None and obj==None:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n*********************** In Partial Query *************************\")\n",
    "    doc_subj = nlp(str(subj))\n",
    "    doc_pred = nlp(str(pred))\n",
    "    doc_obj = nlp(str(obj))\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    r3 = False\n",
    "    \n",
    "    for token_subj in doc_subj:\n",
    "        # get the URI for partial subj\n",
    "        if len(doc_subj)>1:\n",
    "            print(\"\\nFor partial subject \\\"\" + token_subj.text + \"\\\":\")\n",
    "            part_subj = QueryURI(token_subj.text)\n",
    "        else:\n",
    "            part_subj = subjURI\n",
    "            \n",
    "        for token_pred in doc_pred:\n",
    "            # get the URI for partial pred\n",
    "            if len(doc_pred)>1:\n",
    "                print(\"\\nFor partial predicate \\\"\" + token_pred.text + \"\\\":\")\n",
    "                part_pred = QueryURI(token_pred.text)\n",
    "            else:\n",
    "                part_pred = predURI\n",
    "                \n",
    "            for token_obj in doc_obj:\n",
    "                #print(token_obj.text, token_obj.lemma_, token_obj.pos_, token_obj.tag_, token_obj.dep_,\n",
    "                #      token_obj.shape_, token_obj.is_alpha, token_obj.is_stop)\n",
    "                if token_subj.is_stop and token_pred.is_stop and token_obj.is_stop:\n",
    "                    continue\n",
    "                    \n",
    "                # get the URI for partial obj\n",
    "                if len(doc_obj)>1:\n",
    "                    print(\"\\nFor partial object \\\"\" + token_obj.text + \"\\\":\")\n",
    "                    part_obj = QueryURI(token_obj.text)\n",
    "                else:\n",
    "                    part_obj = objURI\n",
    "\n",
    "                r1 = ComponentQuery1(part_subj, part_pred, part_obj)\n",
    "                print(r1)\n",
    "                if r1 and len(r1)>0:\n",
    "                    r2 = ComponentQuery2(part_subj, part_pred, part_obj)\n",
    "                    if r2 and len(r2)>0:\n",
    "                        r3 = ComponentQuery3(part_subj, part_pred, part_obj)\n",
    "                        if r3:\n",
    "                            print(\"\\nFind triple with 3 components:\")\n",
    "                            print(part_subj + \" - \" + part_pred + \" - \" + part_obj)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"\\nFind triple with 2 components:\")\n",
    "                            PrintQueryResult(r2)\n",
    "                    else:\n",
    "                        print(\"\\nFind triple with 1 components:\")\n",
    "                        PrintQueryResult(r1)\n",
    "                        '''if part_subj != None:\n",
    "                            print(part_subj[1:len(part_subj)-1])\n",
    "                        if part_pred != None:\n",
    "                            print(part_pred[1:len(part_pred)-1])\n",
    "                        if part_obj != None:\n",
    "                            print(part_obj[1:len(part_obj)-1])'''\n",
    "                        \n",
    "    return len(r1)>0 or len(r2)>0 or r3\n",
    "\n",
    "def PrintQueryResult(results):\n",
    "    for result in results:\n",
    "        for var in result.vars:\n",
    "            print(var.toPython())\n",
    "        for binding in result.bindings:\n",
    "            print(binding.toPython())\n",
    "        \n",
    "# load Spacy NLP dictionary\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load DBPD ontology and construct graph for query\n",
    "m_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "m_onto = m_world.get_ontology(\"dbpedia.owl\").load()\n",
    "m_graph = m_world.as_rdflib_graph()\n",
    "\n",
    "# load data\n",
    "file = open(\"shortdataset.csv\", \"r\")\n",
    "#file = open(\"newdataset_formatted.csv\", \"r\")\n",
    "reader = csv.reader(file)\n",
    "senSet = []\n",
    "for item in reader:\n",
    "    #format sentences in item as string\n",
    "    fullP = \"\".join(item)\n",
    "    splitP = fullP.split(\";\", 3);\n",
    "    splitS = splitP[3][1:len(splitP[3])].split(\".\");\n",
    "    #print(splitS)\n",
    "    for sen in splitS:\n",
    "        senSet.append(sen)#store the sentence into an array\n",
    "file.close()\n",
    "print(\"Total sentences: \" + str(len(senSet)))\n",
    "\n",
    "# pre-processing\n",
    "PreProcess(senSet)\n",
    "\n",
    "# parse and query each sentence\n",
    "#for index in range(len(senSet)):\n",
    "index = 2\n",
    "sampleSentence = \"Nurses are females\"\n",
    "\n",
    "# extract triple from current sentence\n",
    "#[subj, pred, obj] = ExtractTriple(sampleSentence)\n",
    "[subj, pred, obj] = ExtractTriple(senSet[index])\n",
    "print('Triple to Query: \\n' + subj + ' - ' + pred + ' - ' + obj)\n",
    "\n",
    "# parse with AllenNLP\n",
    "'''from allennlp.predictors import Predictor\n",
    "predictor = Predictor.from_path(\"srl-model-2018.05.25.tar.gz\")\n",
    "results = predictor.predict(senSet[index])\n",
    "for verb in zip(results[\"verbs\"]):\n",
    "    print(f\"{verb}\")\n",
    "#for word, verb in zip(results[\"words\"], results[\"verbs\"]):\n",
    "#    print(f\"{word}\\t{verb}\")\n",
    "'''\n",
    "#for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "#    print(f\"{word}\\t{tag}\")\n",
    "\n",
    "#subj = \"province link\"\n",
    "if pred == \"be\":\n",
    "    pred = \"type\"\n",
    "#obj = \"person\"\n",
    "\n",
    "# look up the URI for subj, pred and obj\n",
    "print(\"\\nFor subject \\\"\" + subj + \"\\\":\")\n",
    "subjURI = QueryURI(subj)\n",
    "print(\"\\nFor predicate \\\"\" + pred + \"\\\":\")\n",
    "predURI = QueryURI(pred)\n",
    "print(\"\\nFor object \\\"\" + obj + \"\\\":\")\n",
    "objURI = QueryURI(obj)\n",
    "\n",
    "try:\n",
    "    print(\"\\n\")\n",
    "    print(\"subject: \" + subjURI[1:len(subjURI)-1])\n",
    "    print(\"predicate: \" + predURI[1:len(predURI)-1])\n",
    "    print(\"object: \" + objURI[1:len(objURI)-1])\n",
    "except:\n",
    "    print(\"none\")\n",
    "    \n",
    "# query the triple in dbpd with SPARQL\n",
    "# queryResult = QueryTriple(subj, pred, obj)\n",
    "# print('Triple Query Result: ' + str(queryResult))\n",
    "\n",
    "# query the triple with several different methods\n",
    "r3 = ComponentQuery3(subjURI, predURI, objURI)\n",
    "if r3:\n",
    "    print(\"\\nFind origin component:\")\n",
    "    print(subj + ' - ' + pred + ' - ' + obj)\n",
    "else:\n",
    "    r2 = ComponentQuery2(subjURI, predURI, objURI)\n",
    "    if r2 and len(r2)>0:\n",
    "        print(\"\\nFind 2 components:\")\n",
    "        PrintQueryResult(r2)\n",
    "    else:\n",
    "        result = PartialQuery(subj, pred, obj, subjURI, predURI, objURI)\n",
    "        if not result:\n",
    "            print (\"Find nothing\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to remove WARNINGs from Owlready2\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/senator belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.MemberOfParliament, DUL.sameSettingAs]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/politicGovernmentDepartment belongs to more than one entity types (e.g. Class, Property, Individual): [owl.ObjectProperty, dbpedia.Department, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/productShape belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasQuality]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/latinName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6391Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6393Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/iso6392Code belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.LanguageCode]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/ingredientName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, DUL.hasPart]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: http://dbpedia.org/ontology/greekName belongs to more than one entity types (e.g. Class, Property, Individual): [owl.DataProperty, dbpedia.Name]; I'm trying to fix it...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "DESCRIBE not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b27ce1a90687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m DESCRIBE ?sub WHERE {\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m?\u001b[0m\u001b[0msub\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m  \u001b[0mdbpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvince\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m }\"\"\"))\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         return result(processor.query(\n\u001b[0;32m-> 1089\u001b[0;31m             query_object, initBindings, initNs, **kwargs))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     def update(self, update_object, processor='sparql',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/processor.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrOrQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevalQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitBindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalQuery\u001b[0;34m(graph, query, initBindings, base)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevalPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/rdflib/plugins/sparql/evaluate.py\u001b[0m in \u001b[0;36mevalPart\u001b[0;34m(ctx, part)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DescribeQuery'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DESCRIBE not implemented'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: DESCRIBE not implemented"
     ]
    }
   ],
   "source": [
    "# reference: https://pythonhosted.org/Owlready2/world.html\n",
    "from owlready2 import *\n",
    "import rdflib\n",
    "\n",
    "my_world = World()# Owlready2 stores every triples in a ‘World’ object\n",
    "onto = my_world.get_ontology(\"dbpedia.owl\").load()\n",
    "\n",
    "graph = my_world.as_rdflib_graph()\n",
    "print(len(graph))\n",
    "\n",
    "prefix = \"\"\"\n",
    "PREFIX rdf:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpd:<http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "SELECT ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "'''r = list(graph.query(prefix + \"\"\"\n",
    "ASK {\n",
    "  dbpd:provinceLink rdf:range  dbpd:Province.\n",
    "}\"\"\"))'''\n",
    "\n",
    "r = list(graph.query(prefix + \"\"\"\n",
    "DESCRIBE ?sub WHERE {\n",
    "  ?sub rdf:range  dbpd:Province.\n",
    "}\"\"\"))\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1b3009c9f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrevlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrevlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d1b3009c9f39>\u001b[0m in \u001b[0;36mrevlist\u001b[0;34m(alist)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mblist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "a =[1,2,3,4,5]\n",
    "\n",
    "def revlist(alist):\n",
    "    blist=[]\n",
    "    a=len(alist)\n",
    "    b=0\n",
    "    blist[b]=alist[a-1]\n",
    "    b=b+1\n",
    "    a=a-1\n",
    "    if len(alist) != len(blist):\n",
    "        return revlist(alist)\n",
    "    \n",
    "revlist(a)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
